{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sa1syo/NLTK/blob/main/IRNLP2019_Ex05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJD7t-7kVlLG"
      },
      "source": [
        "# Exercise 5. Word Sense II (Ch.5.1-4)\n",
        "\n",
        "For International Students: goto http://www.nltk.org/book/ch05.html\n",
        "Almost corresponded about:\n",
        "\n",
        "- Lesson 1: 5.1\n",
        "- Lesson 2: 5.2 \n",
        "- Lesson 3: 5.3\n",
        "- Lesson 4: 5.4\n",
        "\n",
        "(★ Assignment Remark): Please read carefully about 5.2.8, 5.3.2, 5.4.1 and 5.4.2\n",
        "\n",
        "Today's Topic:\n",
        "\n",
        " - Analysis of part of speech and POS tagging\n",
        " - How to use Dictionary in NLTK\n",
        " - How to get POS tag automatically by NLTK Tagger/ Regular expression tagging and lookup tagging\n",
        "\n",
        "本日のトピック:\n",
        "\n",
        " - 品詞分解とタグ: 品詞の種類, タグ付けの仕方\n",
        " - PythonにおけるDictionaryの使い方\n",
        " - NLTK Taggerの利用方法: 正規表現タグ, ルックアップタグ\n",
        " \n",
        "n-gram tagはDocument Modelと深いかかわりがあるので、次回行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QajHzn7HVlLO"
      },
      "source": [
        "# 5. Categorizing and Tagging Words\n",
        "## 5.1. Using a Tagger\n",
        "\n",
        "品詞 (Part of Speech)を付ける: 品詞タグ付け（POS-Tagger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHtSUWRmVlLP"
      },
      "source": [
        "POS-Tagger: 文中の単語に対して品詞タグをつける。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crjpaz8aVlLQ",
        "outputId": "122587d8-f7da-4de4-9513-48b4fb8b9fbd"
      },
      "source": [
        "#from __future__ import division  # Python 2 users only\n",
        "import nltk, re, pprint\n",
        "nltk.download('all')\n",
        "\n",
        "text1 = nltk.word_tokenize(\"And now for something completely different\")\n",
        "print(nltk.pos_tag(text1))\n",
        "text2 = nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
        "print(nltk.pos_tag(text2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'), ('completely', 'RB'), ('different', 'JJ')]\n",
            "[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTNmUNV2VlLR"
      },
      "source": [
        "2例目において、REFUSEとPERMITの両方が現在時制動詞（VBP）と名詞（NN）として表示されることに注意してください。例えば、REFUSEは一方で「拒否」という意味の動詞であるREFUSEは、同時に「ゴミ」を意味する名詞としての機能も持ちます。したがって、POSタグを正しく理解するには、どちらの意味が使用されているかを知る必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1s8B8z0VlLS",
        "outputId": "2e96a95c-3b06-48c8-ee2c-b05772f904b8"
      },
      "source": [
        "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
        "print('Similar/woman: ')\n",
        "text.similar('woman')\n",
        "print('Similar/bought: ')\n",
        "text.similar('bought')\n",
        "print('Similar/over: ')\n",
        "text.similar('over')\n",
        "print('Similar/the: ')\n",
        "text.similar('the')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similar/woman: \n",
            "man time day year car moment world house family child country boy\n",
            "state job place way war girl work word\n",
            "Similar/bought: \n",
            "made said done put had seen found given left heard was been brought\n",
            "set got that took in told felt\n",
            "Similar/over: \n",
            "in on to of and for with from at by that into as up out down through\n",
            "is all about\n",
            "Similar/the: \n",
            "a his this their its her an that our any all one these my in your no\n",
            "some other and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMqAK1ZAVlLS"
      },
      "source": [
        "text.similar() メソッドは単語 wを与えると, wと同じコンテキストを持つ他の単語 w_1 w_2 ... 等の全てを検索します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFoIv_4CVlLT"
      },
      "source": [
        "## 5.2. タグ付きコーパス\n",
        "### 5.2.1. タグ付きトークンの表現\n",
        "str2tuple(): タグ付きトークンの標準文字列表現から、Tupleを作成。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHVoPyu1VlLT",
        "outputId": "885e1543-5237-43b9-9f39-fa993b28db45"
      },
      "source": [
        "tagged_token = nltk.tag.str2tuple('fly/NN')\n",
        "print(tagged_token)\n",
        "print(tagged_token[0])\n",
        "print(tagged_token[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('fly', 'NN')\n",
            "fly\n",
            "NN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJuEUXM-VlLU"
      },
      "source": [
        "インラインでのタグ表現に対して、個々の単語/タグ文字列に分解して、それらをstr2tuple()を用いることでTupleに変換。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LfPrhJBVlLU",
        "outputId": "d5a1e2b9-1dc6-4e6e-f57f-ea08729042fe"
      },
      "source": [
        "sent = '''\n",
        "The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n",
        "other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n",
        "Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n",
        "said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n",
        "accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n",
        "interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n",
        "'''\n",
        "print([nltk.tag.str2tuple(t) for t in sent.split()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'AT'), ('grand', 'JJ'), ('jury', 'NN'), ('commented', 'VBD'), ('on', 'IN'), ('a', 'AT'), ('number', 'NN'), ('of', 'IN'), ('other', 'AP'), ('topics', 'NNS'), (',', ','), ('AMONG', 'IN'), ('them', 'PPO'), ('the', 'AT'), ('Atlanta', 'NP'), ('and', 'CC'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('purchasing', 'VBG'), ('departments', 'NNS'), ('which', 'WDT'), ('it', 'PPS'), ('said', 'VBD'), ('``', '``'), ('ARE', 'BER'), ('well', 'QL'), ('operated', 'VBN'), ('and', 'CC'), ('follow', 'VB'), ('generally', 'RB'), ('accepted', 'VBN'), ('practices', 'NNS'), ('which', 'WDT'), ('inure', 'VB'), ('to', 'IN'), ('the', 'AT'), ('best', 'JJT'), ('interest', 'NN'), ('of', 'IN'), ('both', 'ABX'), ('governments', 'NNS'), (\"''\", \"''\"), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BamBXRK-VlLV"
      },
      "source": [
        "### 5.2.2. タグ付きコーパスの読み方\n",
        "Brown Corpus: 既に品詞タグがつけられている\n",
        " - Brown CorpusのTextを開くと下記のようにインライン型でタグが併記されている。\n",
        "\n",
        "    The/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd / no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\n",
        "    \n",
        "品詞タグは大文字(Brown Corpusの記法が標準型となったため、このようになっている。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqgJAEA9VlLV",
        "outputId": "cc54ade6-1983-4317-a6b4-142c10de11e6"
      },
      "source": [
        "print(nltk.corpus.brown.tagged_words())\n",
        "print(nltk.corpus.brown.tagged_words(tagset='universal'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n",
            "[('The', 'DET'), ('Fulton', 'NOUN'), ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl5TDNmfVlLW",
        "outputId": "99d7701c-a9c8-465c-d7f1-ec3382e567af"
      },
      "source": [
        "print(nltk.corpus.nps_chat.tagged_words())\n",
        "print(nltk.corpus.conll2000.tagged_words())\n",
        "print(nltk.corpus.treebank.tagged_words())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('now', 'RB'), ('im', 'PRP'), ('left', 'VBD'), ...]\n",
            "[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ...]\n",
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wmEHo8lVlLW"
      },
      "source": [
        "タグセットが異なる場合がある (この場合は, target=''でタグセットを指定する）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfIRm70mVlLW",
        "outputId": "570c0f5a-d326-4c82-db21-3363f419fda1"
      },
      "source": [
        "print(nltk.corpus.brown.tagged_words(tagset='universal'))\n",
        "print(nltk.corpus.treebank.tagged_words(tagset='universal'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'DET'), ('Fulton', 'NOUN'), ...]\n",
            "[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOugDkN2VlLX"
      },
      "source": [
        "他の言語のタグ付きコーパスの読み込み例\n",
        " - このページではマルチバイトも表現できるが、Pythonのインターフェースによっては文字化けが起きる場合もある。（コーパスがダウンロードされていない場合は動きません）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCfYpeeWVlLX",
        "outputId": "00eae700-cb10-414e-e242-7e7c9c14f2e4"
      },
      "source": [
        "print(nltk.corpus.sinica_treebank.tagged_words()) #中文\n",
        "print(nltk.corpus.indian.tagged_words()) # インド\n",
        "print(nltk.corpus.mac_morpho.tagged_words()) # ポルトガル語\n",
        "print(nltk.corpus.conll2002.tagged_words()) # CONLL2002による自動判別コーパス\n",
        "print(nltk.corpus.cess_cat.tagged_words()) # カタラン語"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('一', 'Neu'), ('友情', 'Nad'), ('嘉珍', 'Nba'), ...]\n",
            "[('মহিষের', 'NN'), ('সন্তান', 'NN'), (':', 'SYM'), ...]\n",
            "[('Jersei', 'N'), ('atinge', 'V'), ('média', 'N'), ...]\n",
            "[('Sao', 'NC'), ('Paulo', 'VMI'), ('(', 'Fpa'), ...]\n",
            "[('El', 'da0ms0'), ('Tribunal_Suprem', 'np0000o'), ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVKOGhXlVlLX"
      },
      "source": [
        "### 5.2.3. ユニバーサル品詞タグセット\n",
        "ユニバーサル品詞タグセットのの表\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1txMFOnVlLX",
        "outputId": "eec75f4f-5281-4497-cc76-7cfb40a96c8b"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
        "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
        "print(tag_fd.most_common())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('NOUN', 30654), ('VERB', 14399), ('ADP', 12355), ('.', 11928), ('DET', 11389), ('ADJ', 6706), ('ADV', 3349), ('CONJ', 2717), ('PRON', 2535), ('PRT', 2264), ('NUM', 2166), ('X', 92)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-4qt3aGVlLY"
      },
      "source": [
        "### 5.2.4. Nouns\n",
        "名詞は人、場所、物、概念を指す。名詞はDETとADJの後に現れ、VBの主語または目的語になる事が出来る。\n",
        "\n",
        "幾つかの名詞を含む構文パターン\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChLPXoNCVlLY",
        "outputId": "1d23d3ec-db92-42b8-a2ea-3042d08aa343"
      },
      "source": [
        "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
        "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN']\n",
        "fdist = nltk.FreqDist(noun_preceders)\n",
        "print([tag for (tag, _) in fdist.most_common()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NOUN', 'DET', 'ADJ', 'ADP', '.', 'VERB', 'CONJ', 'NUM', 'ADV', 'PRT', 'PRON', 'X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxnmxIkWVlLY"
      },
      "source": [
        "### 5.2.4. Verbs\n",
        "動詞は事象や行動を記述する。文脈において、動詞は典型的には一つまたは複数の名詞句の指示対象を含む関係を表す。\n",
        "\n",
        "いくつかの動詞を含む構文パターン\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p349bAUVVlLY",
        "outputId": "d9472420-ba69-4252-e429-deb2bef5bf55"
      },
      "source": [
        "wsj = nltk.corpus.treebank.tagged_words(tagset='universal')\n",
        "word_tag_fd = nltk.FreqDist(wsj)\n",
        "print([wt[0] for (wt, _) in word_tag_fd.most_common() if wt[1] == 'VERB'][:100]) # 動詞最頻順100件まで出力"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['is', 'said', 'was', 'are', 'be', 'has', 'have', 'will', 'says', 'would', 'were', 'had', 'been', 'could', \"'s\", 'can', 'do', 'say', 'make', 'may', 'did', 'rose', 'made', 'does', 'expected', 'buy', 'take', 'get', 'might', 'sell', 'added', 'sold', 'help', 'including', 'should', 'reported', 'according', 'pay', 'compared', 'being', 'fell', 'began', 'based', 'used', 'closed', \"'re\", 'want', 'see', 'took', 'yield', 'offered', 'set', 'priced', 'approved', 'come', 'noted', 'cut', 'ended', 'found', 'increased', 'become', 'think', 'named', 'go', 'trying', 'proposed', 'received', 'growing', 'declined', 'held', 'give', 'came', 'use', 'put', 'making', 'continue', 'raise', 'estimated', 'called', 'paid', 'designed', 'going', 'expects', 'seeking', 'must', 'plans', 'wo', 'increasing', 'saying', 'got', 'owns', 'trading', 'acquired', 'gained', 'fined', 'reached', 'holding', 'announced', 'filed', 'became']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50p_ssKqVlLZ"
      },
      "source": [
        "単語とタグはペアになっているため、単語を条件として、タグをイベントとして処理し、条件とイベントのペアのリストを使用して条件付き頻度分布を初期化できます。これにより、単語が指定されたタグの頻度順リストが表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkygEq1zVlLZ",
        "outputId": "653ff48a-1419-4e3b-9bdb-d286b8d46b15"
      },
      "source": [
        "cfd1 = nltk.ConditionalFreqDist(wsj)\n",
        "print(cfd1['yield'].most_common())\n",
        "print(cfd1['cut'].most_common())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('VERB', 28), ('NOUN', 20)]\n",
            "[('VERB', 25), ('NOUN', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsPe5jJvVlLZ"
      },
      "source": [
        "タグが条件として、単語がイベントとするように、ペアの順序を逆にすることができます。これで、指定されたタグに当てはまる単語を確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6Wcylj_VlLa",
        "outputId": "43585dd8-9803-41c9-8210-f11ecc05087b"
      },
      "source": [
        "wsj = nltk.corpus.treebank.tagged_words()\n",
        "cfd1 = nltk.ConditionalFreqDist(wsj)\n",
        "cfd2 = nltk.ConditionalFreqDist((tag, word) for (word, tag) in wsj)\n",
        "print(list(cfd2['VBN'])[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['named', 'used', 'caused', 'exposed', 'reported', 'replaced', 'sold', 'died', 'expected', 'diagnosed', 'studied', 'industrialized', 'owned', 'found', 'classified', 'rejected', 'outlawed', 'imported', 'tracked', 'thought', 'considered', 'elected', 'based', 'lifted', 'ensnarled', 'voted', 'been', 'held', 'banned', 'renovated', 'prolonged', 'recorded', 'accumulated', 'offered', 'become', 'guaranteed', 'proposed', 'related', 'improved', 'worried', 'cluttered', 'expedited', 'retired', 'ordered', 'collected', 'required', 'received', 'moved', 'determined', 'made', 'changed', 'completed', 'disputed', 'refunded', 'estimated', 'compared', 'located', 'filed', 'scrapped', 'anticipated', 'priced', 'set', 'applied', 'existed', 'incurred', 'reached', 'Regarded', 'paid', 'trained', 'instituted', 'vowed', 'deemed', 'combined', 'removed', 'concerned', 'complained', 'accelerated', 'believed', 'called', 'solved', 'forgiven', 'launched', 'built', 'preferred', 'raised', 'scheduled', 'brought', 'increased', 'developed', 'led', 'approved', 'produced', 'denied', 'requested', 'covered', 'assembled', 'achieved', 'maintained', 'left', 'assisted']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSmKVHHeVlLb"
      },
      "source": [
        "VBD（過去時制）とVBN （過去分詞）の違いを明確にするために、VBDと VBNの両方になり得る単語を見つけて、周囲のテキストを見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfxXiGoLVlLc",
        "outputId": "e4c581ae-b0c4-459d-b268-3939e9fdc919"
      },
      "source": [
        "print([w for w in cfd1.conditions() if 'VBD' in cfd1[w] and 'VBN' in cfd1[w]])\n",
        "idx1 = wsj.index(('kicked', 'VBD'))\n",
        "print('kicked-VBD; ', wsj[idx1-4:idx1+1])\n",
        "idx2 = wsj.index(('kicked', 'VBN'))\n",
        "print('kicked-VBS; ', wsj[idx2-4:idx2+1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['named', 'used', 'caused', 'reported', 'said', 'stopped', 'heard', 'studied', 'led', 'replaced', 'sold', 'worked', 'died', 'found', 'rejected', 'imposed', 'made', 'dumped', 'imported', 'mixed', 'described', 'continued', 'ended', 'thought', 'reached', 'had', 'approved', 'completed', 'suspended', 'lifted', 'dropped', 'voted', 'settled', 'decided', 'followed', 'welcomed', 'held', 'banned', 'pointed', 'squeezed', 'fed', 'registered', 'released', 'increased', 'forecast', 'recorded', 'announced', 'offered', 'lowered', 'spent', 'proposed', 'got', 'added', 'noted', 'turned', 'closed', 'retired', 'ordered', 'required', 'received', 'moved', 'determined', 'changed', 'upheld', 'set', 'estimated', 'compared', 'opened', 'tied', 'filed', 'disclosed', 'anticipated', 'attached', 'called', 'applied', 'favored', 'posted', 'paid', 'removed', 'accelerated', 'placed', 'vowed', 'deemed', 'prompted', 'complained', 'believed', 'met', 'solved', 'launched', 'built', 'triggered', 'developed', 'entered', 'acquired', 'preferred', 'raised', 'scheduled', 'brought', 'started', 'produced', 'denied', 'covered', 'maintained', 'left', 'cut', 'bought', 'snapped', 'put', 'boosted', 'issued', 'agreed', 'surged', 'ranged', 'kicked', 'scrambled', 'plunged', 'climbed', 'invested', 'jumped', 'owed', 'lent', 'stressed', 'failed', 'indicated', 'asked', 'intended', 'helped', 'awarded', 'purchased', 'provided', 'polled', 'included', 'blamed', 'contributed', 'read', 'fired', 'committed', 'learned', 'carried', 'identified', 'endorsed', 'renewed', 'confirmed', 'terminated', 'planned', 'contained', 'condemned', 'managed', 'viewed', 'needed', 'killed', 'presented', 'speculated', 'hit', 'opposed', 'refused', 'wanted', 'created', 'introduced', 'accused', 'tried', 'involved', 'responded', 'quoted', 'tripled', 'passed', 'matched', 'won', 'treated', 'alleged', 'concluded', 'surfaced', 'restructured', 'advised', 'told', 'feared', 'meant', 'returned', 'advanced', 'discovered', 'dismissed', 'allowed', 'aimed', 'referred', 'represented', 'threatened', 'controlled', 'hampered', 'nominated', 'assured', 'damaged', 'gained', 'merged', 'signed', 'lost', 'argued', 'sent', 'formed', 'obtained', 'mounted', 'adopted', 'sparked', 'served', 'understood', 'accepted', 'fueled', 'limited', 'Asked', 'extended', 'kept', 'rolled', 'chastised', 'printed', 'expanded', 'sweetened', 'barred', 'reduced', 'declared', 'soared', 'remarked', 'forced', 'stated', 'finished', 'eliminated', 'cited', 'collapsed', 'earned', 'licensed', 'secured', 'omitted', 'assumed', 'stepped', 'switched', 'felt', 'expressed', 'discussed', 'invented', 'observed', 'hired', 'expelled', 'consented', 'backed', 'reflected', 'sought', 'negotiated', 'resulted', 'proved', 'examined', 'dominated', 'pushed', 'supported', 'attributed', 'attempted', 'obligated', 'halted', 'transformed', 'marketed', 'rated', 'warned', 'edged', 'bribed']\n",
            "kicked-VBD;  [('While', 'IN'), ('program', 'NN'), ('trades', 'NNS'), ('swiftly', 'RB'), ('kicked', 'VBD')]\n",
            "kicked-VBS;  [('head', 'NN'), ('of', 'IN'), ('state', 'NN'), ('has', 'VBZ'), ('kicked', 'VBN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfuRV4T7VlLc"
      },
      "source": [
        "この場合、kickの過去分詞の前に、助動詞haveの形式があります。これは一般的に本当だろうか？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAvc32B5VlLd"
      },
      "source": [
        "### 5.2.6. Adjectives and Adverbs\n",
        "形容詞は名詞を説明し、または述語となる機能を持ちます。英語の形容詞は、内部構造を持ちます。副詞は動詞で記述されているイベントの時間、方法、場所や方向を指定するために動詞を変更する機能を持ちます。\n",
        "\n",
        "### 5.2.7. Unsimplified Tags\n",
        "各名詞の品詞タイプの中で最も頻繁に使用される名詞を見つけましょう。以下のプログラムは、NNで始まるすべてのタグを検出し、各タグにいくつかのサンプル単語を提供します。NNには多くのバリアントがあることがわかります。最も重要なものには 、所有名詞の場合は$、複数名詞の場合はS（複数名詞は通常sで終わるため）、および固有名詞の場合はPが含まれます。また、タグのほとんどは、接尾辞の修飾子があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w7fvbHQVlLd",
        "outputId": "5c971e8c-9ad1-431b-fc58-3e78d855cd7d"
      },
      "source": [
        "def findtags(tag_prefix, tagged_text):\n",
        "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
        "                                  if tag.startswith(tag_prefix))\n",
        "    return dict((tag, cfd[tag].most_common(5)) for tag in cfd.conditions())\n",
        "\n",
        "tagdict = findtags('NN', nltk.corpus.brown.tagged_words(categories='news'))\n",
        "for tag in sorted(tagdict):\n",
        "    print(tag, tagdict[tag])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN [('year', 137), ('time', 97), ('state', 88), ('week', 85), ('man', 72)]\n",
            "NN$ [(\"year's\", 13), (\"world's\", 8), (\"state's\", 7), (\"nation's\", 6), (\"city's\", 6)]\n",
            "NN$-HL [(\"Golf's\", 1), (\"Navy's\", 1)]\n",
            "NN$-TL [(\"President's\", 11), (\"Administration's\", 3), (\"Army's\", 3), (\"League's\", 3), (\"University's\", 3)]\n",
            "NN-HL [('sp.', 2), ('problem', 2), ('Question', 2), ('cut', 2), ('party', 2)]\n",
            "NN-NC [('ova', 1), ('eva', 1), ('aya', 1)]\n",
            "NN-TL [('President', 88), ('House', 68), ('State', 59), ('University', 42), ('City', 41)]\n",
            "NN-TL-HL [('Fort', 2), ('Mayor', 1), ('Commissioner', 1), ('City', 1), ('Oak', 1)]\n",
            "NNS [('years', 101), ('members', 69), ('people', 52), ('sales', 51), ('men', 46)]\n",
            "NNS$ [(\"children's\", 7), (\"women's\", 5), (\"men's\", 3), (\"janitors'\", 3), (\"taxpayers'\", 2)]\n",
            "NNS$-HL [(\"Dealers'\", 1), (\"Idols'\", 1)]\n",
            "NNS$-TL [(\"Women's\", 4), (\"States'\", 3), (\"Giants'\", 2), (\"Princes'\", 1), (\"Bombers'\", 1)]\n",
            "NNS-HL [('Wards', 1), ('deputies', 1), ('bonds', 1), ('aspects', 1), ('Decisions', 1)]\n",
            "NNS-TL [('States', 38), ('Nations', 11), ('Masters', 10), ('Communists', 9), ('Rules', 9)]\n",
            "NNS-TL-HL [('Nations', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0AMZe6MVlLe"
      },
      "source": [
        "### 5.2.8. Exploring Tagged Corpora\n",
        "(★ Assignment Remark) 前の章で見たコーパスの種類の探索に簡単に戻りましょう。今回はPOSタグを活用します。  \n",
        "'Learned'の単語の頻度を見て、テキストでどのように使用されているかを確認したいとします。これは、頻繁に続く言葉を抽出するようにします。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-73p-6uEVlLe",
        "outputId": "b4a6f168-e9d1-43c5-bbd0-9b9b2dd596c4"
      },
      "source": [
        "brown_learned_text = brown.words(categories='learned')\n",
        "print(sorted(set(b for (a, b) in nltk.bigrams(brown_learned_text) if a == 'often')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[',', '.', 'accomplished', 'analytically', 'appear', 'apt', 'associated', 'assuming', 'became', 'become', 'been', 'began', 'call', 'called', 'carefully', 'chose', 'classified', 'colorful', 'composed', 'contain', 'differed', 'difficult', 'encountered', 'enough', 'equate', 'extremely', 'found', 'happens', 'have', 'ignored', 'in', 'involved', 'more', 'needed', 'nightly', 'observed', 'of', 'on', 'out', 'quite', 'represent', 'responsible', 'revamped', 'seclude', 'set', 'shortened', 'sing', 'sounded', 'stated', 'still', 'sung', 'supported', 'than', 'to', 'when', 'work']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtAWAxwaVlLf",
        "outputId": "a0e8f260-8419-4099-83c5-0ce054b4fa76"
      },
      "source": [
        "brown_lrnd_tagged = brown.tagged_words(categories='learned', tagset='universal')\n",
        "tags = [b[1] for (a, b) in nltk.bigrams(brown_lrnd_tagged) if a[0] == 'often']\n",
        "fd = nltk.FreqDist(tags)\n",
        "fd.tabulate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VERB  ADV  ADP  ADJ    .  PRT \n",
            "  37    8    7    6    4    2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbcGulyHVlLg"
      },
      "source": [
        "より大きなコンテキストを見て、タグと単語の特定のシーケンスを含む単語（この場合は\"<Verb> to <Verb>\"）を見つけましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK5K8dh3VlLg",
        "outputId": "077afd42-e36b-49ec-e7de-04bc41f42b9d"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "list1 = [] # for counting <verb> to <verb> expression\n",
        "def process(sentence):\n",
        "    for (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(sentence):\n",
        "        if (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):\n",
        "            print(w1, w2, w3)\n",
        "            list1.append((w1,w2,w3))\n",
        "for tagged_sent in brown.tagged_sents()[:100]: # [:100]で出力結果を100件まで絞っている。全て抽出したい場合はここを消去。\n",
        "    if len(tagged_sent) > 1:\n",
        "        process(tagged_sent)\n",
        "print(len(list1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combined to achieve\n",
            "continue to place\n",
            "serve to protect\n",
            "wanted to wait\n",
            "allowed to place\n",
            "expected to become\n",
            "expected to approve\n",
            "expected to make\n",
            "intends to make\n",
            "seek to set\n",
            "like to see\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV3r5QT5VlLh"
      },
      "source": [
        "# Exercise Attendance\n",
        "\n",
        "Please print all found words involving particular sequences of tags and words (in this case \"<Verb> to <Verb>\") such as upper code.   \n",
        "    (same as the delete [:100] part)   \n",
        "Also count the line number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI2F58-SVlLh"
      },
      "source": [
        "品詞タグの部分に関して非常に曖昧な単語を探すコード。そのような単語が各コンテキストにあるときにタグ付けされる理由を理解することは、タグ間の区別を明確にするのに役立つ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2V11vUGVlLh",
        "outputId": "da111efa-7443-4eb8-f14c-07735f8b169b"
      },
      "source": [
        "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
        "data = nltk.ConditionalFreqDist((word.lower(), tag)\n",
        "                                for (word, tag) in brown_news_tagged)\n",
        "for word in sorted(data.conditions()):\n",
        "    if len(data[word]) > 3:\n",
        "        tags = [tag for (tag, _) in data[word].most_common()]\n",
        "        print(word, ' '.join(tags))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best ADJ ADV VERB NOUN\n",
            "close ADV ADJ VERB NOUN\n",
            "open ADJ VERB NOUN ADV\n",
            "present ADJ ADV NOUN VERB\n",
            "that ADP DET PRON ADV\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofwnHJA0VlLi"
      },
      "source": [
        "## 5.3. Mapping Words to Properties Using Python Dictionaries\n",
        "Exercise 1で、既にDictionaryについては触れていますが、ここではDictionaryを使って効果的にNLTKを利用し、言語リソースにアクセスすることを学びます。\n",
        "\n",
        "### 5.3.1. Indexing Lists and Dictionaries\n",
        "テキストはPythonでは単語のリストとして扱われます。リストの重要な特性は、text1[100]などのインデックスを指定することで特定のアイテムを「ルックアップ」できることです。数値を指定し、単語を取得する方法に注目してください。\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oug4PG0UVlLi"
      },
      "source": [
        "連想配列を用いると、このIndexをKeywordで置き換えることができ、非常に簡単に探索できます。例えば、頻度分布等を考えるとき、WordをIndexとして用い、Word Countを値として取得することが出来ます。\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtFWJ3E_VlLi"
      },
      "source": [
        "連想配列において、Indexに当たる部分をKey, 値をValueとして、Key-Valueの関係のデータベースを構築することができます。以下の表は、言語リソースに対して連想配列を用いる場合のKey-Valueの候補を示します。\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMZww08AVlLi"
      },
      "source": [
        "### 5.3.2. Dictionaries in Python\n",
        "以下のコードは、PythonのDictionaryの利用方法です。詳細は特に示しませんが、以下のような使い方ができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWUVZaySVlLj",
        "outputId": "ab257e1e-cf17-4e05-f0ce-6fc9256972a6"
      },
      "source": [
        "pos = {}\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXwX1MUgVlLj",
        "outputId": "1e2e771d-e695-4c02-f147-d7a530061594"
      },
      "source": [
        "pos['colorless'] = 'ADJ'\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'colorless': 'ADJ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsJ3FhbJVlLj",
        "outputId": "22e0b7ec-3d47-4900-cdcd-badeb4df0cdb"
      },
      "source": [
        "pos['ideas'] = 'N'\n",
        "pos['sleep'] = 'V'\n",
        "pos['furiously'] = 'ADV'\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvHI2sS9VlLk",
        "outputId": "ca6bc280-5413-4f42-ed9a-959a85c6afcf"
      },
      "source": [
        "print(pos['ideas'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACm_Yn9VlLk",
        "outputId": "527d0524-4f74-47bb-f2b3-7898119bc0ab"
      },
      "source": [
        "print(pos['colorless'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ADJ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa5Zaa0SVlLk"
      },
      "source": [
        "以下のように、要素のないKeyを探索しようとするとErrorになります。つまり、必ずDictionaryに含まれているKeyを把握しなければいけないので、Keyの検査が必要になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r6VqZ2DVlLl",
        "outputId": "eaee2f70-0c53-4191-f1bc-1ac6c3aeb8bf"
      },
      "source": [
        "print('green' in pos) # Keyの検査の一例: in を使うと分かるので、これをIF文で用いる\n",
        "if('green' in pos):\n",
        "    print(pos['green']) # これをしようとするとErrorになる（確認してみてください）"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GimHUcLuVlLm"
      },
      "source": [
        "Dictionaryからlistに変更可能 (そのまま扱うとKeyのリストが出てくる。Valueのリストを取り出したい場合は指定する必要がある）\n",
        "itemをtupleにするにはitems()を使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyXI9UajVlLm",
        "outputId": "4849ea38-cc69-476e-e547-a80d2c907634"
      },
      "source": [
        "print(list( pos))\n",
        "print(list(pos.keys()))\n",
        "print(list(pos.values()))\n",
        "print(list(pos.items()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['colorless', 'ideas', 'sleep', 'furiously']\n",
            "['colorless', 'ideas', 'sleep', 'furiously']\n",
            "['ADJ', 'N', 'V', 'ADV']\n",
            "[('colorless', 'ADJ'), ('ideas', 'N'), ('sleep', 'V'), ('furiously', 'ADV')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3FWyZfoVlLn"
      },
      "source": [
        "(★ Assignment Remark) sorted()メソッドを使うと昇順にソート可能。（降順もある）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpY8in5uVlLn",
        "outputId": "9adfc30e-c140-4f3b-e0f2-3307ff69a1af"
      },
      "source": [
        "print(sorted(pos))\n",
        "print(sorted(pos,reverse=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['colorless', 'furiously', 'ideas', 'sleep']\n",
            "['sleep', 'ideas', 'furiously', 'colorless']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKDVk6z_VlLn"
      },
      "source": [
        "Inline形式でendswidth()メソッドを出す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPiP0fCaVlLo",
        "outputId": "01732b72-ae70-4473-c651-d321e2adb92f"
      },
      "source": [
        "print([w for w in pos if w.endswith('s')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['colorless', 'ideas']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPI88j9KVlLo"
      },
      "source": [
        "以下の2つは同じ出力になる。tupleを用いると分かりやすい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZruXwCJVlLo",
        "outputId": "e122dd92-72ef-42ff-c497-3f49c5ced1a1"
      },
      "source": [
        "for word in sorted(pos):\n",
        "    print(word + \":\", pos[word])\n",
        "print(\"\")\n",
        "for key, val in sorted(pos.items()):\n",
        "    print(key + \":\", val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "colorless: ADJ\n",
            "furiously: ADV\n",
            "ideas: N\n",
            "sleep: V\n",
            "\n",
            "colorless: ADJ\n",
            "furiously: ADV\n",
            "ideas: N\n",
            "sleep: V\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2svXlsmvVlLo"
      },
      "source": [
        "### 5.3.3. Defining Dictionaries\n",
        "Dctionaryを定義するやり方はいくつか存在する。そのままDictionaryを記述する方法と、dictメソッドを呼び出す方法がある。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqJFMdbJVlLo",
        "outputId": "5bd78f20-1bbd-47b1-9949-904afb1f5e30"
      },
      "source": [
        "pos = {'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n",
        "print(pos)\n",
        "pos = dict(colorless='ADJ', ideas='N', sleep='V', furiously='ADV')\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n",
            "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh-eHPxxVlLp"
      },
      "source": [
        "リストはKeyになれない。しかし、TupleはKeyになれる\n",
        "\n",
        "    >>> pos = {['ideas', 'blogs', 'adventures']: 'N'}\n",
        "\n",
        "    ---------------------------------------------------------------------------\n",
        "    TypeError                                 Traceback (most recent call last)\n",
        "    <ipython-input-56-2280db643563> in <module>\n",
        "    ----> 1 print(pos = {['ideas', 'blogs', 'adventures']: 'N'})\n",
        "    \n",
        "    TypeError: unhashable type: 'list'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgMcMEV5VlLp",
        "outputId": "d821cfc1-bd6e-4b28-9045-0594c5a38513"
      },
      "source": [
        "pos = {('ideas', 'blogs', 'adventures'): 'N'}\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('ideas', 'blogs', 'adventures'): 'N'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDnBX_g1VlLq"
      },
      "source": [
        "### 5.3.4. Default Dictionaries\n",
        "辞書にないキーにアクセスしようとすると、エラーが発生します。ただし、辞書がこの新しいキーのエントリを自動的に作成し、ゼロや空のリストなどのデフォルト値を与えることができる場合に役立ちます。このため、defaultdictと呼ばれる特別な種類の辞書が利用可能です。これを使用するには、デフォルト値を作成するために使用できるパラメーター、たとえばint、float、str、list、dict、 tupleを指定する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21908SmkVlLq",
        "outputId": "5aab292d-14f9-42bb-cbba-44f05db2414f"
      },
      "source": [
        "from collections import defaultdict\n",
        "frequency = defaultdict(int)\n",
        "frequency['colorless'] = 4\n",
        "print(frequency['ideas'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPrKBejYVlLq",
        "outputId": "777ed760-d5e5-4b5c-f06f-f830bcd1a1ef"
      },
      "source": [
        "pos = defaultdict(list)\n",
        "pos['sleep'] = ['NOUN', 'VERB']\n",
        "print(pos['ideas'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugbe54DjVlLr",
        "outputId": "75ae9cff-82b2-4475-d54b-e6923344ae4c"
      },
      "source": [
        "pos = defaultdict(lambda: 'NOUN')\n",
        "pos['colorless'] = 'ADJ'\n",
        "print(pos['blog'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jECYGOOIVlLr",
        "outputId": "e139949e-7d4e-4029-e1ce-702b91f9ace0"
      },
      "source": [
        "print(list(pos.items()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('colorless', 'ADJ'), ('blog', 'NOUN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNnoUwVBVlLs",
        "outputId": "52cbcfc3-2d4d-4f54-ac7f-93c651801084"
      },
      "source": [
        "alice = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
        "vocab = nltk.FreqDist(alice)\n",
        "v1000 = [word for (word, _) in vocab.most_common(1000)]\n",
        "mapping = defaultdict(lambda: 'UNK')\n",
        "for v in v1000:\n",
        "    mapping[v] = v\n",
        "\n",
        "alice2 = [mapping[v] for v in alice]\n",
        "print(alice2[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'UNK', 'UNK', 'UNK', 'UNK', 'CHAPTER', 'I', '.', 'Down', 'the', 'Rabbit', '-', 'UNK', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'UNK', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\", 'So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te0MzT1rVlLs",
        "outputId": "d3d087cb-ddb5-4d60-e39a-3e8dbe7723f3"
      },
      "source": [
        "print(len(set(alice2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsKMfNbCVlLs"
      },
      "source": [
        "### 5.3.5. Incrementally Updating a Dictionary\n",
        "辞書を使用して出現回数をカウントし、fig-tallyに示す単語を集計する方法をエミュレートできます。空のdefaultdictを初期化することから始め、テキスト内の各品詞タグを処理します。タグが以前に見られなかった場合、デフォルトでカウントはゼロになります。タグに遭遇するたびに、+= 演算子を使用してそのカウントをインクリメントします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysV62t-GVlLs",
        "outputId": "8a677304-3eda-407c-b242-3ee079421fab"
      },
      "source": [
        "from collections import defaultdict\n",
        "counts = defaultdict(int)\n",
        "from nltk.corpus import brown\n",
        "for (word, tag) in brown.tagged_words(categories='news', tagset='universal'):\n",
        "    counts[tag] += 1\n",
        "print(counts['NOUN'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X4geC3dVlLt",
        "outputId": "0ba8b808-8e98-4920-98a3-32f8d608e241"
      },
      "source": [
        "print(sorted(counts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iwe5txQVVlLt",
        "outputId": "d46f7c30-4893-4f38-ab31-baf4088da057"
      },
      "source": [
        "from operator import itemgetter\n",
        "print(sorted(counts.items(), key=itemgetter(1), reverse=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('NOUN', 30654), ('VERB', 14399), ('ADP', 12355), ('.', 11928), ('DET', 11389), ('ADJ', 6706), ('ADV', 3349), ('CONJ', 2717), ('PRON', 2535), ('PRT', 2264), ('NUM', 2166), ('X', 92)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT3XKFdnVlLt",
        "outputId": "1f8481bc-39f0-477b-f67f-31ff598a9239"
      },
      "source": [
        "print([t for t, c in sorted(counts.items(), key=itemgetter(1), reverse=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NOUN', 'VERB', 'ADP', '.', 'DET', 'ADJ', 'ADV', 'CONJ', 'PRON', 'PRT', 'NUM', 'X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o6PVOpYVlLt",
        "outputId": "b59154cf-757b-4f24-90e6-363ab778f82b"
      },
      "source": [
        "pair = ('NP', 8336)\n",
        "print(pair[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEhLD8uGVlLu",
        "outputId": "cc3a5fa6-7d03-4633-aa43-d5a4e6773d4c"
      },
      "source": [
        "print(itemgetter(1)(pair))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2kuM6i7VlLu"
      },
      "source": [
        "最後の2文字に従って単語にインデックスを付けます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvLichafVlLu",
        "outputId": "cf83a7ca-f126-48c2-ef66-a93e6be88736"
      },
      "source": [
        "last_letters = defaultdict(list)\n",
        "words = nltk.corpus.words.words('en')\n",
        "for word in words:\n",
        "    key = word[-2:]\n",
        "    last_letters[key].append(word)\n",
        "print(last_letters['ly'][:100])\n",
        "print(last_letters['zy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abactinally', 'abandonedly', 'abasedly', 'abashedly', 'abashlessly', 'abbreviately', 'abdominally', 'abhorrently', 'abidingly', 'abiogenetically', 'abiologically', 'abjectly', 'ableptically', 'ably', 'abnormally', 'abominably', 'aborally', 'aboriginally', 'abortively', 'aboundingly', 'abridgedly', 'abruptedly', 'abruptly', 'abscondedly', 'absently', 'absentmindedly', 'absolutely', 'absolutistically', 'absorbedly', 'absorbingly', 'absorptively', 'abstemiously', 'abstinently', 'abstractedly', 'abstractively', 'abstractly', 'abstrusely', 'absurdly', 'abundantly', 'abusedly', 'abusefully', 'abusively', 'abysmally', 'academically', 'acceleratedly', 'accentually', 'acceptably', 'acceptedly', 'accessarily', 'accessibly', 'accessively', 'accessorily', 'accidentally', 'accidently', 'accommodately', 'accommodatingly', 'accordantly', 'accordingly', 'accountably', 'accumulatively', 'accurately', 'accursedly', 'accusably', 'accusatively', 'accusatorially', 'accusingly', 'accustomedly', 'acervately', 'acetometrically', 'achingly', 'achromatically', 'acicularly', 'acidimetrically', 'acidly', 'acknowledgedly', 'acoustically', 'acquiescently', 'acquiescingly', 'acquisitively', 'acridly', 'acrimoniously', 'acrobatically', 'acrocephaly', 'acrogenously', 'acrologically', 'acromegaly', 'acronically', 'acropetally', 'acrostically', 'actinally', 'actinically', 'actinoelectrically', 'actionably', 'actively', 'actually', 'actuarially', 'acutely', 'Adamically', 'adaptationally', 'adaptively']\n",
            "['blazy', 'bleezy', 'blowzy', 'boozy', 'breezy', 'bronzy', 'buzzy', 'Chazy', 'cozy', 'crazy', 'dazy', 'dizzy', 'dozy', 'enfrenzy', 'fezzy', 'fizzy', 'floozy', 'fozy', 'franzy', 'frenzy', 'friezy', 'frizzy', 'frowzy', 'furzy', 'fuzzy', 'gauzy', 'gazy', 'glazy', 'groszy', 'hazy', 'heezy', 'Izzy', 'jazzy', 'Jozy', 'lawzy', 'lazy', 'mazy', 'mizzy', 'muzzy', 'nizy', 'oozy', 'quartzy', 'quizzy', 'refrenzy', 'ritzy', 'Shortzy', 'sizy', 'sleazy', 'sneezy', 'snoozy', 'squeezy', 'Suzy', 'tanzy', 'tizzy', 'topazy', 'trotcozy', 'twazzy', 'unbreezy', 'unfrizzy', 'wheezy', 'woozy', 'wuzzy', 'yezzy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSsuZa84VlLu"
      },
      "source": [
        "同じパターンを使用してアナグラム辞書を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmBLW_QtVlLu",
        "outputId": "8806f8e3-89be-4d96-8f80-09b79dd25784"
      },
      "source": [
        "anagrams = defaultdict(list)\n",
        "for word in words:\n",
        "    key = ''.join(sorted(word))\n",
        "    anagrams[key].append(word)\n",
        "print(anagrams['aeilnrt'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['entrail', 'latrine', 'ratline', 'reliant', 'retinal', 'trenail']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j20kK1YaVlLv"
      },
      "source": [
        "このような単語の蓄積は非常に一般的なタスクであるため、NLTKはnltk.Index（）の形式でdefaultdict（list）を作成するより便利な方法を提供します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGi_jxxgVlLv",
        "outputId": "09af807d-aaed-4bb5-e768-9dee751b03f6"
      },
      "source": [
        "anagrams = nltk.Index((''.join(sorted(w)), w) for w in words)\n",
        "print(anagrams['aeilnrt'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['entrail', 'latrine', 'ratline', 'reliant', 'retinal', 'trenail']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTKEICnbVlLv"
      },
      "source": [
        "### 5.3.6. Complex Keys and Values\n",
        "複雑なキーと値を持つデフォルトの辞書を使用できます。単語自体、および前の単語のタグが与えられた場合、その単語の可能なタグの範囲を調べてみましょう。POSタガーがこの情報をどのように使用できるかを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koohEd_QVlLv",
        "outputId": "b0f037e0-351e-423d-ef77-60d3e0e191d3"
      },
      "source": [
        "pos = defaultdict(lambda: defaultdict(int))\n",
        "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
        "for ((w1, t1), (w2, t2)) in nltk.bigrams(brown_news_tagged):\n",
        "    pos[(t1, w2)][t2] += 1\n",
        "print(pos[('DET', 'right')] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {'NOUN': 5, 'ADJ': 11})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHVIxpvsVlLw"
      },
      "source": [
        "この例では、int() のdefaultdict()を使用しています。タグ付きコーパスのバイグラムをどのように反復し、各反復ごとに単語とタグのペアのペアを処理することに注意してください。ループを通過するたびに、（t1、w2）、タグ、およびそれに続く wordのpos辞書のエントリを更新しました。posで項目を検索するとき、複合キーを指定する必要があり、辞書オブジェクトを取得します。POSタガーは、そのような情報を使用して、決定子が先行する場合、単語rightをADJとしてタグ付けすることを決定できます。\n",
        "\n",
        "### 5.3.7. Inverting a Dictionary\n",
        "Dictionaryの逆引きを行う例を示す。通常、Keyを指定してValueを高速に取得できるようにするのがDictionaryだが、逆引き（Valueを指定してKeyを取得）は遅い。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MipIUfxEVlLw",
        "outputId": "e0a9c644-9a39-464e-c917-57c29fad3a2f"
      },
      "source": [
        "counts = defaultdict(int)\n",
        "for word in nltk.corpus.gutenberg.words('milton-paradise.txt'):\n",
        "    counts[word] += 1\n",
        "print([key for (key, value) in counts.items() if value == 32])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mortal', 'Against', 'Him', 'There', 'brought', 'King', 'virtue', 'every', 'been', 'thine']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpedByJmVlLw"
      },
      "source": [
        "以下はKeyとValueを逆転したDictionaryを形成し、逆引きを行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktLbhbXvVlLx",
        "outputId": "1648caa2-4856-4709-9b23-3ea96dc2a4f1"
      },
      "source": [
        "pos = {'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n",
        "pos2 = dict((value, key) for (key, value) in pos.items())\n",
        "print(pos2['N'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ideas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u45NOWjNVlLx"
      },
      "source": [
        "Defaultdictを用いた例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w2Jih-AVlLx",
        "outputId": "ce84b204-4a41-4df3-e891-2111a2589e7d"
      },
      "source": [
        "pos.update({'cats': 'N', 'scratch': 'V', 'peacefully': 'ADV', 'old': 'ADJ'})\n",
        "pos2 = defaultdict(list)\n",
        "for key, value in pos.items():\n",
        "    pos2[value].append(key)\n",
        "print(pos2['ADV'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['furiously', 'peacefully']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeHBZ8syVlLy"
      },
      "source": [
        "Python's Dictionary Methods: A summary of commonly-used methods and idioms involving dictionaries.![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0WTsPX0VlLy"
      },
      "source": [
        "## 5.4. Automatic Tagging\n",
        "さて、今回の本題のAutomatid Taggingについて見ていきます。品詞タグをテキストに自動的に追加するために、幾つかの典型的なタガーを見ていくことにします。なお、単語のタグは、単語と文内のコンテキストに依存することがわかります。このため、単語ではなくタグ付き文のレベルでデータを処理します。まず、使用するデータをロードします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vFwwECGVlLz"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
        "brown_sents = brown.sents(categories='news')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuHIQ-dPVlLz"
      },
      "source": [
        "### 5.4.1. The Default Tagger\n",
        "最も単純なタガーは、各トークンに同じタグを割り当てます。これはかなり平凡なステップのように思えるかもしれませんが、タガーのパフォーマンスの重要なベースラインを確立します。最良の結果を得るために、各単語に最も可能性の高いタグを付けます。どのタグが最も可能性が高いかを調べてみましょう（単純化されていないタグセットを使用しています）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8dEu9vNVlLz",
        "outputId": "500bf85d-42b4-4eb0-9fec-0d57b1bf4bdf"
      },
      "source": [
        "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
        "print(nltk.FreqDist(tags).max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpmp_VeEVlLz"
      },
      "source": [
        "これを用いると、全ての単語にNNとしてタグをつけるタガーを製作できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNfe3dwkVlL0",
        "outputId": "3e05e3d4-f49e-4b00-e5a0-dbcbd2cec112"
      },
      "source": [
        "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
        "tokens = nltk.word_tokenize(raw)\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "print(default_tagger.tag(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('I', 'NN'), ('do', 'NN'), ('not', 'NN'), ('like', 'NN'), ('green', 'NN'), ('eggs', 'NN'), ('and', 'NN'), ('ham', 'NN'), (',', 'NN'), ('I', 'NN'), ('do', 'NN'), ('not', 'NN'), ('like', 'NN'), ('them', 'NN'), ('Sam', 'NN'), ('I', 'NN'), ('am', 'NN'), ('!', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71NnuoJsVlL0"
      },
      "source": [
        "(★ Assignment Remark) 当然ながら、この方法のパフォーマンスは酷く劣ります。評価を行うと、トークンの約1/8だけが正しくタグ付けされます（つまり、名詞（NN）を保持する単語トークンは1/8ある、と言うことです。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQWknjpWVlL0",
        "outputId": "ecdd474e-64f0-4e42-a855-8b300510ef2f"
      },
      "source": [
        "print(default_tagger.evaluate(brown_tagged_sents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.13089484257215028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-rHGfXli5dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA0gdkgNVlL0"
      },
      "source": [
        "### 5.4.2. The Regular Expression Tagger\n",
        "続いて、正規表現を用いたタガーを作成してみましょう。正規表現タガーは、一致するパターンに基づいてタグをトークンに割り当てます。たとえば、edで終わる単語は動詞の過去分詞であり、sで終わる単語は所有名詞であると 推測できます。これらを正規表現のリストとして表現できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twLohWewVlL0"
      },
      "source": [
        "patterns = [\n",
        "     (r'.*ing$', 'VBG'),               # gerunds\n",
        "     (r'.*ed$', 'VBD'),                # simple past\n",
        "     (r'.*es$', 'VBZ'),                # 3rd singular present\n",
        "     (r'.*ould$', 'MD'),               # modals\n",
        "     (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
        "     (r'.*s$', 'NNS'),                 # plural nouns\n",
        "     (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
        "     (r'.*', 'NN')                     # nouns (default)\n",
        " ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFQIl9hdVlL1"
      },
      "source": [
        "(★ Assignment Remark) これらは順番に処理され、最初に一致したものが適用されることに注意してください。これで、タガーを設定し、それを使用して文にタグを付けることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uajnNxQ2VlL1",
        "outputId": "02e18ce4-82c6-4419-d040-89736c6f9d65"
      },
      "source": [
        "regexp_tagger = nltk.RegexpTagger(patterns)\n",
        "print(regexp_tagger.tag(brown_sents[3]))\n",
        "print(regexp_tagger.evaluate(brown_tagged_sents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('``', 'NN'), ('Only', 'NN'), ('a', 'NN'), ('relative', 'NN'), ('handful', 'NN'), ('of', 'NN'), ('such', 'NN'), ('reports', 'NNS'), ('was', 'NNS'), ('received', 'VBD'), (\"''\", 'NN'), (',', 'NN'), ('the', 'NN'), ('jury', 'NN'), ('said', 'NN'), (',', 'NN'), ('``', 'NN'), ('considering', 'VBG'), ('the', 'NN'), ('widespread', 'NN'), ('interest', 'NN'), ('in', 'NN'), ('the', 'NN'), ('election', 'NN'), (',', 'NN'), ('the', 'NN'), ('number', 'NN'), ('of', 'NN'), ('voters', 'NNS'), ('and', 'NN'), ('the', 'NN'), ('size', 'NN'), ('of', 'NN'), ('this', 'NNS'), ('city', 'NN'), (\"''\", 'NN'), ('.', 'NN')]\n",
            "0.20326391789486245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkbD0dl2VlL1"
      },
      "source": [
        "最終的な正規表現« 。* »は、すべてを名詞としてタグ付けするキャッチオールです。これは、デフォルトのタガーと同等です（効率が大幅に低下します）。これを正規表現タガーの一部として再指定する代わりに、このタガーをデフォルトのタガーと組み合わせる方法はありますか？これを行う方法については、後ほど説明します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyRcIz8KVlL2"
      },
      "source": [
        "### 5.4.3. The Lookup Tagger\n",
        "多くの高頻度単語にはNNタグがありません。最も頻繁に使用される100個の単語を見つけて、最も可能性の高いタグを保存しましょう。次に、この情報を「ルックアップタガー」（NLTK UnigramTagger）のモデルとして使用できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLadf4WLVlL2",
        "outputId": "be768171-bbf1-4574-f90a-862c8446a940"
      },
      "source": [
        "fd = nltk.FreqDist(brown.words(categories='news'))\n",
        "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
        "most_freq_words = fd.most_common(100)\n",
        "likely_tags = dict((word, cfd[word].max()) for (word, _) in most_freq_words)\n",
        "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
        "print(baseline_tagger.evaluate(brown_tagged_sents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.45578495136941344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UamNHiBBVlL2"
      },
      "source": [
        "100個の最も頻繁に使用される単語のタグを知るだけで、トークンの大部分（実際にはほぼ半分）を正しくタグ付けできるようになったことは驚くことではありません(ある意味一番ナイーブな機械学習と言えます)。タグのない入力テキストで何が行われるのか見てみましょう："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBWwSv12VlL2",
        "outputId": "ab27cb13-8388-44d9-c4db-ec8db20f4722"
      },
      "source": [
        "sent = brown.sents(categories='news')[3]\n",
        "print(baseline_tagger.tag(sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('``', '``'), ('Only', None), ('a', 'AT'), ('relative', None), ('handful', None), ('of', 'IN'), ('such', None), ('reports', None), ('was', 'BEDZ'), ('received', None), (\"''\", \"''\"), (',', ','), ('the', 'AT'), ('jury', None), ('said', 'VBD'), (',', ','), ('``', '``'), ('considering', None), ('the', 'AT'), ('widespread', None), ('interest', None), ('in', 'IN'), ('the', 'AT'), ('election', None), (',', ','), ('the', 'AT'), ('number', None), ('of', 'IN'), ('voters', None), ('and', 'CC'), ('the', 'AT'), ('size', None), ('of', 'IN'), ('this', 'DT'), ('city', None), (\"''\", \"''\"), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AofPuosVlL2"
      },
      "source": [
        "多くの単語には、最も頻繁に使用される100個の単語に含まれていないため、Noneというタグが割り当てられています。これらの場合、デフォルトのタグNNを割り当てたいと思います。つまり、最初にルックアップテーブルを使用し、タグを割り当てることができない場合は、デフォルトのタガーを使用します。これは、backoff（5）と呼ばれるプロセスです。これを行うには、以下に示すように、一方のタガーを他方のパラメーターとして指定します。これで、ルックアップタガーは名詞以外の単語の単語とタグのペアのみを保存し、単語にタグを割り当てることができない場合は常にデフォルトのタガーを呼び出します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxGOte5CVlL2",
        "outputId": "02278dd2-3b4f-4a17-8ffe-5053c1695d19"
      },
      "source": [
        "baseline_tagger = nltk.UnigramTagger(model=likely_tags,backoff=nltk.DefaultTagger('NN'))\n",
        "print(baseline_tagger.tag(sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('``', '``'), ('Only', 'NN'), ('a', 'AT'), ('relative', 'NN'), ('handful', 'NN'), ('of', 'IN'), ('such', 'NN'), ('reports', 'NN'), ('was', 'BEDZ'), ('received', 'NN'), (\"''\", \"''\"), (',', ','), ('the', 'AT'), ('jury', 'NN'), ('said', 'VBD'), (',', ','), ('``', '``'), ('considering', 'NN'), ('the', 'AT'), ('widespread', 'NN'), ('interest', 'NN'), ('in', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('the', 'AT'), ('number', 'NN'), ('of', 'IN'), ('voters', 'NN'), ('and', 'CC'), ('the', 'AT'), ('size', 'NN'), ('of', 'IN'), ('this', 'DT'), ('city', 'NN'), (\"''\", \"''\"), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn_pesucVlL3"
      },
      "source": [
        "これらすべてをまとめて、以下のようなサイズの範囲を持つルックアップタガーを作成および評価するプログラムを作成しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7_Koog_VlL3",
        "outputId": "41563c7d-ef0c-4ba0-9a6e-bf02f2972fa5"
      },
      "source": [
        "def performance(cfd, wordlist):\n",
        "    lt = dict((word, cfd[word].max()) for word in wordlist)\n",
        "    baseline_tagger = nltk.UnigramTagger(model=lt, backoff=nltk.DefaultTagger('NN'))\n",
        "    return baseline_tagger.evaluate(brown.tagged_sents(categories='news'))\n",
        "\n",
        "def display():\n",
        "    import pylab\n",
        "    word_freqs = nltk.FreqDist(brown.words(categories='news')).most_common()\n",
        "    words_by_freq = [w for (w, _) in word_freqs]\n",
        "    cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
        "    sizes = 2 ** pylab.arange(15)\n",
        "    perfs = [performance(cfd, words_by_freq[:size]) for size in sizes]\n",
        "    pylab.plot(sizes, perfs, '-bo')\n",
        "    pylab.title('Lookup Tagger Performance with Varying Model Size')\n",
        "    pylab.xlabel('Model Size')\n",
        "    pylab.ylabel('Performance')\n",
        "    pylab.show()\n",
        "\n",
        "display()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3TJYo_VlL4"
      },
      "source": [
        "### 5.4.4. Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk_yVzo7VlL4"
      },
      "source": [
        "上記の例では、精度スコアに重点が置かれている。特に、以下のパイプラインの図のように考えてみると、1つのモジュールの術力エラーはDown Stream Moduleで大幅に増加します。\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        " - 人間の専門家が割り当てるタグと比較して、Taggerのパフォーマンスを評価する\n",
        " - 我々CSの人間はLanguage Studyの専門家ではなく、そうした人的資源にアクセスしにくい。\n",
        " - 代わりに Gold Standardとされている一般化されたテストデータで対応する。これは、手動で注釈が付けられ、自動システムの推測が評価される基準として受け入れられているコーパス。特定の単語に対して推測するタグがゴールドスタンダードタグと同じである場合、タガーは正しいと見なされる。\n",
        "\n",
        "もちろん、オリジナルのゴールドスタンダードアノテーションを設計および実行した人間は人間だけでした。さらに分析すると、ゴールドスタンダードの誤りが示される場合があり、最終的にはタグセットの改訂やガイドラインの詳細化につながる可能性があります。それにもかかわらず、Automated Taggerの評価に関する限り、ゴールドスタンダードは定義上「正しい」ものです。"
      ]
    }
  ]
}