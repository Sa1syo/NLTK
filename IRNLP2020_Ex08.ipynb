{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sa1syo/NLTK/blob/main/IRNLP2020_Ex08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOFWxEhPUDZ6"
      },
      "source": [
        "# Exercise 7. Document Classification (Ch.6)\n",
        "\n",
        "For International Students: goto http://www.nltk.org/book/ch06.html Almost corresponded about:\n",
        "\n",
        "Lesson 1: 6.1 Supervised Classification (Exercise Attendance)  \n",
        "Lesson 2: 6.2 Further Examples of Supervised Classification  \n",
        "Lesson 3: 6.3 Evaluation  \n",
        "Lesson 4: 6.4 Decision Trees  \n",
        "(★ Assignment Remark): Please read carefully about 6.1. expecially 6.1.4, 6.1.6\n",
        "\n",
        "Today's Topic:\n",
        "\n",
        "- Some examples to utilize classification in NLTK\n",
        "- Some examples of Supervised Classification\n",
        "- How to make evaluation on each dataset\n",
        "\n",
        "Please notice about each exmaple takes so long time to process in this exercise.\n",
        "\n",
        "本日のトピック:\n",
        "\n",
        "- NLTKに実装されているClassificationアルゴリズムの利用例\n",
        "- その他Supervised Classificationの実行例\n",
        "- データセットに対する評価尺度と手法\n",
        "\n",
        "注意) この章辺りから、Document全体の計算をするので、1度1度のプロセスに時間がかかります。各回、終わるまで少々お待ちください。\n",
        "\n",
        "この章の目的は、以下の質問に答えることです。\n",
        "\n",
        "1. どのようにして分類する際に顕著な言語データの特定の特徴を特定することができますか？\n",
        "2. どのようにして言語処理タスクを自動的に実行するために使用できる言語のモデルを構築することができますか？\n",
        "3. これらのモデルから言語について何を学ぶことができますか？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD7kMiI9UDaA"
      },
      "source": [
        "from __future__ import division  # Python 2 users only\n",
        "import nltk, re, pprint\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbkkGXXDUDaA"
      },
      "source": [
        "注意) この章辺りから、Document全体の計算をするので、1度1度のプロセスに時間がかかります。各回、終わるまで少々お待ちください。\n",
        "\n",
        "\n",
        "## Lesson 1. Supervised Classification\n",
        "\n",
        "Classification (分類) は、特定の入力に対して正しいクラスラベルを選択するタスクです。基本的な分類タスクでは、各入力は他のすべての入力から分離して考慮され、ラベルのセットは事前に定義されます。分類タスクの例を次に示します。\n",
        "\n",
        "- メールがスパムかどうかを判断します。\n",
        "- 「スポーツ」、「テクノロジー」、「政治」などのトピック領域の固定リストから、ニュース記事のトピックを決定します。\n",
        "- 銀行という単語の特定の出現が、川岸、金融機関、側に傾く行為、または金融機関に何かを預ける行為を指すのに使用されるかどうかを決定します。\n",
        "\n",
        "基本的な分類タスクには、いくつかの興味深い違いがあります。たとえば、マルチクラス分類では、各インスタンスに複数のラベルを割り当てることができます。オープンクラス分類では、ラベルのセットは事前に定義されていません。また、シーケンス分類では、入力のリストが一緒に分類されます。\n",
        "\n",
        "分類器は、各入力の正しいラベルを含むコーパスのトレーニングに基づいて構築される場合、教師ありと呼ばれます。教師あり分類で使用されるフレームワークを以下に示します。\n",
        "\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "\n",
        "### 1.1. Gender Identification (Exercise 4で既に実施)\n",
        "\n",
        "以下は既に行った、Naive Bayesによる名前からの性別の特定についての例です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDX7Z9ZzUDaB",
        "outputId": "b539e760-3151-4da1-b4b9-c5fcbb5c96f7"
      },
      "source": [
        "nltk.download('names')\n",
        "from nltk.corpus import names\n",
        "import random\n",
        "\n",
        "def gender_features(word):\n",
        "    return {'last_letter': word[-1]}\n",
        "\n",
        "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
        "    [(name, 'female') for name in names.words('female.txt')])\n",
        "\n",
        "random.shuffle(labeled_names)\n",
        "\n",
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "print('Neo: ', classifier.classify(gender_features('Neo')))\n",
        "print('Trinity: ', classifier.classify(gender_features('Trinity')))\n",
        "print('Overall: ', nltk.classify.accuracy(classifier, test_set))\n",
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "Neo:  male\n",
            "Trinity:  female\n",
            "Overall:  0.738\n",
            "Most Informative Features\n",
            "             last_letter = 'k'              male : female =     43.1 : 1.0\n",
            "             last_letter = 'a'            female : male   =     35.8 : 1.0\n",
            "             last_letter = 'v'              male : female =     17.6 : 1.0\n",
            "             last_letter = 'f'              male : female =     14.6 : 1.0\n",
            "             last_letter = 'p'              male : female =     12.6 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eryIB9mjUDaB"
      },
      "source": [
        "- 分類子を作成する最初のステップは、入力のどの 機能が関連するか、および それらの機能をエンコードする方法を決定することです。この例では、特定の名前の最後の文字を見ることから始めます。次の機能抽出 関数は、特定の名前に関する関連情報を含む辞書を作成します。\n",
        "\n",
        "- フィーチャセットとして知られる返されたディクショナリは、フィーチャ名からその値にマッピングします。機能名は、大文字と小文字を区別する文字列で、通常は例の「last_letter」のように、人間が読み取れる機能の短い説明を提供します。フィーチャ値は、ブール値、数値、文字列などの単純なタイプの値です\n",
        "\n",
        "- 最後のリストでは、「a」で終わるトレーニングセットの名前は男性よりも33倍多い女性ですが、「k」で終わる名前は女性より32倍多い男性であることを示しています。これらの比率は尤度比と呼ばれ、さまざまな機能と結果の関係を比較するのに役立ちます。\n",
        "\n",
        "- 大きなコーパスを利用する場合は、全てのインスタンスの機能を含む単一のリストを作成すると、大量のメモリが消費される可能性があります。これらの場合、nltk.classify.applay_faeturesを利用します。これはリストのように利用できるが、全ての機能セットをメモリに保存せずにオブジェクトを返します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kntN3l9dUDaC"
      },
      "source": [
        "from nltk.classify import apply_features\n",
        "train_set = apply_features(gender_features, labeled_names[500:])\n",
        "test_set = apply_features(gender_features, labeled_names[:500])\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set) # データがそのまま利用可能。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yemEmx57UDaC"
      },
      "source": [
        "### 6.1.2. Choosing The Right Feature\n",
        "特徴の選択とデータのエンコーディングの仕方の決定は、適した良いモデルを取る出す能力に非常に大きい影響を与えます。つまり、クラスタリング記述子を作成する際の多くの重要な作業は、関連する特徴の選定と表現能力の担保に他ならないのです。かなりシンプルで明らかな機能セットを使用することで適切なパフォーマンスを得ることができますが、通常は、目の前のタスクを十分に理解した上で、慎重に構築された特徴を使用することで大きなメリットが得られます。  \n",
        "  \n",
        "以下は、人名単語に対する性別を表す特徴を、試行錯誤のプロセスを経て構築する一例です。先ずは、全ての機能を含む『Kitchin Sink』アプローチから初めて、役立つ特徴を確認していきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAyu-CZkUDaC",
        "outputId": "def194d2-e311-4fcb-d2ea-7662757995e4"
      },
      "source": [
        "def gender_features2(name): # 最初と最後の文字に対して取得して調査。\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features\n",
        "\n",
        "print(gender_features2('John') )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'first_letter': 'j', 'last_letter': 'n', 'count(a)': 0, 'has(a)': False, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 0, 'has(d)': False, 'count(e)': 0, 'has(e)': False, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 1, 'has(h)': True, 'count(i)': 0, 'has(i)': False, 'count(j)': 1, 'has(j)': True, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 1, 'has(n)': True, 'count(o)': 1, 'has(o)': True, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 0, 'has(r)': False, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vslO_nDiUDaD"
      },
      "source": [
        "ただし、通常、特定の学習アルゴリズムで使用する特徴数には制限があります。提供する特徴が多すぎる場合、アルゴリズムは一般化されていないトレーニングデータの特異性に依存する可能性が高くなります。この問題は過剰適合として知られており、小さなトレーニングセットで作業する場合に特に問題になる可能性があります。  \n",
        "\n",
        "たとえば、上記genger_feature2に示した特徴抽出器を使用して単純ベイズ分類器をトレーニングすると、比較的小さなトレーニングセットが過剰に適合し、その精度が注目される分類器の精度よりも約1％低いシステムになります。 (時々よくなります）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtUKAkxWUDaD",
        "outputId": "ee73813d-f857-44cf-a7e1-0c0530abe333"
      },
      "source": [
        "random.shuffle(labeled_names)\n",
        "\n",
        "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))\n",
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.768\n",
            "0.752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx_YnkVzUDaD"
      },
      "source": [
        "特徴の初期セットが選択されると、特徴セットを洗練する非常に生産的な方法はエラー分析です。最初に、モデルを作成するためのコーパスデータを含む開発セットを選択します。この開発セットは、トレーニングセットと開発テストセットに細分されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCgW0tJbUDaD"
      },
      "source": [
        "train_names = labeled_names[1500:]\n",
        "devtest_names = labeled_names[500:1500]\n",
        "test_names = labeled_names[:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLV2f9GUDaE"
      },
      "source": [
        "Training Setはモデルのトレーニングに使用され、Dev-Test Setはエラー分析の実行に使用されます。Test Setは、システムの最終評価に役立ちます。以下で説明する理由により、Test Setを使用するだけでなく、エラー分析のために個別のDev-TestSetを使用することが重要です。コーパスデータの異なるサブセットへの分割を下図に示します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk3M8ILyUDaE"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "それを用いて、Traingし、Dev-Testセットで比較します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8fNjWNTUDaE",
        "outputId": "64393430-bbc5-4fa3-e7b3-cec04f73760a"
      },
      "source": [
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTeXao39UDaE"
      },
      "source": [
        "(★ Assignment Remark)\n",
        "\n",
        "Dev-Testセットを用いて、名前の性別を予測するときに、分類器が出力するエラーのリストを生成できます。\n",
        "生成した後、モデルが間違ったラベルを予測した個々のエラーのケースを調べ、どの追加情報が正しい決定を可能にするか（または既存のどの情報がそれをだまして誤った決定を下すのか）を判断しようとします。\n",
        "\n",
        "必要に応じて、特徴セットを調整できます。作成した名前分類器は、dev-testコーパスで約100個のエラーを生成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOPi4iTUDaE",
        "outputId": "86b46a34-8a87-482c-d3b6-247f1a804ca2"
      },
      "source": [
        "errors = []\n",
        "for (name, tag) in devtest_names:\n",
        "    guess = classifier.classify(gender_features(name))\n",
        "    if guess != tag:\n",
        "        errors.append( (tag, guess, name) )\n",
        "for (tag, guess, name) in sorted(errors[:20]): # [:20] は出力調整。外すと全てのリストが出ます。\n",
        "    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct=female   guess=male     name=April                         \n",
            "correct=female   guess=male     name=Cris                          \n",
            "correct=female   guess=male     name=Emmalyn                       \n",
            "correct=female   guess=male     name=Janean                        \n",
            "correct=female   guess=male     name=Kass                          \n",
            "correct=female   guess=male     name=Katalin                       \n",
            "correct=female   guess=male     name=Kipp                          \n",
            "correct=female   guess=male     name=Nariko                        \n",
            "correct=female   guess=male     name=Renel                         \n",
            "correct=female   guess=male     name=Robin                         \n",
            "correct=female   guess=male     name=Roslyn                        \n",
            "correct=female   guess=male     name=Shaun                         \n",
            "correct=male     guess=female   name=Avi                           \n",
            "correct=male     guess=female   name=Barney                        \n",
            "correct=male     guess=female   name=Bentley                       \n",
            "correct=male     guess=female   name=Harvie                        \n",
            "correct=male     guess=female   name=Henrique                      \n",
            "correct=male     guess=female   name=Monte                         \n",
            "correct=male     guess=female   name=Serge                         \n",
            "correct=male     guess=female   name=Sonnie                        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1w1HAFSUDaF"
      },
      "source": [
        "このエラーのリストを調べると、複数の文字のサフィックスが名前の性別を示している可能性があることが明らかになります。たとえば、ynで終わる名前は主に女性であるように見えますが、nで終わる名前は男性である傾向があります。また、hで終わる名前は 女性である傾向がありますが、chで終わる名前は通常男性です。したがって、2文字のサフィックスの機能を含めるように機能抽出ツールを調整します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUu3QtgQUDaF",
        "outputId": "9d2ce47e-1bd4-42fe-a6b7-a95f3c9f53bb"
      },
      "source": [
        "def gender_features(word):\n",
        "    return {'suffix1': word[-1:],\n",
        "            'suffix2': word[-2:]}\n",
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou9yEhrCUDaF"
      },
      "source": [
        "# Exercise Attendance\n",
        "上記では、2文字のSuffixを用いてFeatureとしましたが、3文字分抽出するとどうなるでしょうか？　1文字と2文字、3文字の時の精度を比較してください。\n",
        "(ex)\n",
        "    0.765\n",
        "    0.771\n",
        "    0.771"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVHzjS0KUDaG"
      },
      "source": [
        "### 1.3. Document Classificatoin (Exercise 4で実施済み)\n",
        "\n",
        "続いて、文書に対するクラスタリングを見ていきます。我々は文書がカテゴリで標識されているコーパスの例をいくつか見ました。これらのコーパスを使用して、新しいドキュメントに適切なカテゴリラベルを自動的にタグ付けする分類子を構築できます。まず、適切なカテゴリでラベル付けされたドキュメントのリストを作成します。この例では、各レビューをポジティブまたはネガティブに分類するMovie Reviews Corpusを選択しました。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGXPGZOlUDaG",
        "outputId": "f3f5ee87-0017-4ec6-9dde-66bd9b5ffd64"
      },
      "source": [
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "           for category in movie_reviews.categories()\n",
        "           for fileid in movie_reviews.fileids(category)]\n",
        "random.shuffle(documents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Fi4MnRUDaG"
      },
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qwaFTs4UDaG",
        "outputId": "ed2f41a2-ee76-4352-cd96-0cf2267dbe19"
      },
      "source": [
        "print(document_features(movie_reviews.words('pos/cv957_8737.txt'))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'contains(plot)': True, 'contains(:)': True, 'contains(two)': True, 'contains(teen)': False, 'contains(couples)': False, 'contains(go)': False, 'contains(to)': True, 'contains(a)': True, 'contains(church)': False, 'contains(party)': False, 'contains(,)': True, 'contains(drink)': False, 'contains(and)': True, 'contains(then)': True, 'contains(drive)': False, 'contains(.)': True, 'contains(they)': True, 'contains(get)': True, 'contains(into)': True, 'contains(an)': True, 'contains(accident)': False, 'contains(one)': True, 'contains(of)': True, 'contains(the)': True, 'contains(guys)': False, 'contains(dies)': False, 'contains(but)': True, 'contains(his)': True, 'contains(girlfriend)': True, 'contains(continues)': False, 'contains(see)': False, 'contains(him)': True, 'contains(in)': True, 'contains(her)': False, 'contains(life)': False, 'contains(has)': True, 'contains(nightmares)': False, 'contains(what)': True, \"contains(')\": True, 'contains(s)': True, 'contains(deal)': False, 'contains(?)': False, 'contains(watch)': True, 'contains(movie)': True, 'contains(\")': True, 'contains(sorta)': False, 'contains(find)': False, 'contains(out)': True, 'contains(critique)': False, 'contains(mind)': False, 'contains(-)': True, 'contains(fuck)': False, 'contains(for)': True, 'contains(generation)': False, 'contains(that)': True, 'contains(touches)': False, 'contains(on)': True, 'contains(very)': True, 'contains(cool)': False, 'contains(idea)': True, 'contains(presents)': False, 'contains(it)': True, 'contains(bad)': False, 'contains(package)': False, 'contains(which)': True, 'contains(is)': True, 'contains(makes)': False, 'contains(this)': True, 'contains(review)': False, 'contains(even)': False, 'contains(harder)': False, 'contains(write)': False, 'contains(since)': False, 'contains(i)': False, 'contains(generally)': False, 'contains(applaud)': False, 'contains(films)': False, 'contains(attempt)': False, 'contains(break)': False, 'contains(mold)': False, 'contains(mess)': False, 'contains(with)': True, 'contains(your)': False, 'contains(head)': False, 'contains(such)': False, 'contains(()': True, 'contains(lost)': False, 'contains(highway)': False, 'contains(&)': False, 'contains(memento)': False, 'contains())': True, 'contains(there)': True, 'contains(are)': True, 'contains(good)': False, 'contains(ways)': False, 'contains(making)': True, 'contains(all)': True, 'contains(types)': False, 'contains(these)': False, 'contains(folks)': False, 'contains(just)': True, 'contains(didn)': False, 'contains(t)': False, 'contains(snag)': False, 'contains(correctly)': False, 'contains(seem)': False, 'contains(have)': True, 'contains(taken)': False, 'contains(pretty)': False, 'contains(neat)': False, 'contains(concept)': False, 'contains(executed)': False, 'contains(terribly)': False, 'contains(so)': False, 'contains(problems)': True, 'contains(well)': True, 'contains(its)': False, 'contains(main)': False, 'contains(problem)': False, 'contains(simply)': False, 'contains(too)': False, 'contains(jumbled)': False, 'contains(starts)': False, 'contains(off)': False, 'contains(normal)': False, 'contains(downshifts)': False, 'contains(fantasy)': False, 'contains(world)': True, 'contains(you)': True, 'contains(as)': True, 'contains(audience)': False, 'contains(member)': False, 'contains(no)': False, 'contains(going)': False, 'contains(dreams)': False, 'contains(characters)': False, 'contains(coming)': False, 'contains(back)': False, 'contains(from)': True, 'contains(dead)': False, 'contains(others)': True, 'contains(who)': True, 'contains(look)': True, 'contains(like)': True, 'contains(strange)': False, 'contains(apparitions)': False, 'contains(disappearances)': False, 'contains(looooot)': False, 'contains(chase)': True, 'contains(scenes)': False, 'contains(tons)': False, 'contains(weird)': False, 'contains(things)': True, 'contains(happen)': False, 'contains(most)': True, 'contains(not)': True, 'contains(explained)': False, 'contains(now)': False, 'contains(personally)': False, 'contains(don)': False, 'contains(trying)': False, 'contains(unravel)': False, 'contains(film)': False, 'contains(every)': False, 'contains(when)': True, 'contains(does)': False, 'contains(give)': False, 'contains(me)': True, 'contains(same)': True, 'contains(clue)': False, 'contains(over)': False, 'contains(again)': False, 'contains(kind)': True, 'contains(fed)': False, 'contains(up)': False, 'contains(after)': False, 'contains(while)': True, 'contains(biggest)': False, 'contains(obviously)': False, 'contains(got)': True, 'contains(big)': False, 'contains(secret)': False, 'contains(hide)': False, 'contains(seems)': False, 'contains(want)': False, 'contains(completely)': False, 'contains(until)': False, 'contains(final)': False, 'contains(five)': False, 'contains(minutes)': False, 'contains(do)': True, 'contains(make)': True, 'contains(entertaining)': False, 'contains(thrilling)': False, 'contains(or)': False, 'contains(engaging)': False, 'contains(meantime)': False, 'contains(really)': False, 'contains(sad)': False, 'contains(part)': False, 'contains(arrow)': False, 'contains(both)': False, 'contains(dig)': False, 'contains(flicks)': False, 'contains(we)': False, 'contains(actually)': True, 'contains(figured)': False, 'contains(by)': True, 'contains(half)': False, 'contains(way)': True, 'contains(point)': False, 'contains(strangeness)': False, 'contains(did)': False, 'contains(start)': True, 'contains(little)': True, 'contains(bit)': False, 'contains(sense)': False, 'contains(still)': False, 'contains(more)': False, 'contains(guess)': False, 'contains(bottom)': False, 'contains(line)': False, 'contains(movies)': True, 'contains(should)': False, 'contains(always)': False, 'contains(sure)': False, 'contains(before)': False, 'contains(given)': False, 'contains(password)': False, 'contains(enter)': False, 'contains(understanding)': False, 'contains(mean)': False, 'contains(showing)': False, 'contains(melissa)': False, 'contains(sagemiller)': False, 'contains(running)': False, 'contains(away)': False, 'contains(visions)': False, 'contains(about)': True, 'contains(20)': False, 'contains(throughout)': False, 'contains(plain)': False, 'contains(lazy)': False, 'contains(!)': True, 'contains(okay)': False, 'contains(people)': False, 'contains(chasing)': False, 'contains(know)': False, 'contains(need)': False, 'contains(how)': True, 'contains(giving)': False, 'contains(us)': True, 'contains(different)': False, 'contains(offering)': False, 'contains(further)': False, 'contains(insight)': False, 'contains(down)': False, 'contains(apparently)': False, 'contains(studio)': False, 'contains(took)': False, 'contains(director)': False, 'contains(chopped)': False, 'contains(themselves)': False, 'contains(shows)': False, 'contains(might)': False, 'contains(ve)': False, 'contains(been)': False, 'contains(decent)': False, 'contains(here)': True, 'contains(somewhere)': False, 'contains(suits)': False, 'contains(decided)': False, 'contains(turning)': False, 'contains(music)': False, 'contains(video)': False, 'contains(edge)': False, 'contains(would)': False, 'contains(actors)': False, 'contains(although)': False, 'contains(wes)': False, 'contains(bentley)': False, 'contains(seemed)': False, 'contains(be)': True, 'contains(playing)': True, 'contains(exact)': False, 'contains(character)': False, 'contains(he)': True, 'contains(american)': False, 'contains(beauty)': False, 'contains(only)': True, 'contains(new)': False, 'contains(neighborhood)': False, 'contains(my)': False, 'contains(kudos)': False, 'contains(holds)': False, 'contains(own)': True, 'contains(entire)': False, 'contains(feeling)': False, 'contains(unraveling)': False, 'contains(overall)': False, 'contains(doesn)': False, 'contains(stick)': False, 'contains(because)': False, 'contains(entertain)': False, 'contains(confusing)': False, 'contains(rarely)': False, 'contains(excites)': False, 'contains(feels)': False, 'contains(redundant)': False, 'contains(runtime)': False, 'contains(despite)': False, 'contains(ending)': False, 'contains(explanation)': False, 'contains(craziness)': False, 'contains(came)': False, 'contains(oh)': False, 'contains(horror)': False, 'contains(slasher)': False, 'contains(flick)': False, 'contains(packaged)': False, 'contains(someone)': False, 'contains(assuming)': False, 'contains(genre)': False, 'contains(hot)': False, 'contains(kids)': False, 'contains(also)': True, 'contains(wrapped)': False, 'contains(production)': False, 'contains(years)': False, 'contains(ago)': False, 'contains(sitting)': False, 'contains(shelves)': False, 'contains(ever)': True, 'contains(whatever)': False, 'contains(skip)': False, 'contains(where)': True, 'contains(joblo)': False, 'contains(nightmare)': False, 'contains(elm)': False, 'contains(street)': False, 'contains(3)': False, 'contains(7)': False, 'contains(/)': False, 'contains(10)': False, 'contains(blair)': False, 'contains(witch)': False, 'contains(2)': False, 'contains(crow)': False, 'contains(9)': False, 'contains(salvation)': False, 'contains(4)': False, 'contains(stir)': False, 'contains(echoes)': False, 'contains(8)': False, 'contains(happy)': False, 'contains(bastard)': False, 'contains(quick)': True, 'contains(damn)': False, 'contains(y2k)': False, 'contains(bug)': False, 'contains(starring)': False, 'contains(jamie)': False, 'contains(lee)': False, 'contains(curtis)': False, 'contains(another)': False, 'contains(baldwin)': False, 'contains(brother)': False, 'contains(william)': False, 'contains(time)': False, 'contains(story)': False, 'contains(regarding)': False, 'contains(crew)': False, 'contains(tugboat)': False, 'contains(comes)': False, 'contains(across)': False, 'contains(deserted)': False, 'contains(russian)': False, 'contains(tech)': False, 'contains(ship)': False, 'contains(kick)': False, 'contains(power)': False, 'contains(within)': False, 'contains(gore)': False, 'contains(bringing)': False, 'contains(few)': False, 'contains(action)': True, 'contains(sequences)': False, 'contains(virus)': False, 'contains(empty)': False, 'contains(flash)': False, 'contains(substance)': False, 'contains(why)': False, 'contains(was)': False, 'contains(middle)': False, 'contains(nowhere)': False, 'contains(origin)': False, 'contains(pink)': False, 'contains(flashy)': False, 'contains(thing)': False, 'contains(hit)': False, 'contains(mir)': False, 'contains(course)': True, 'contains(donald)': False, 'contains(sutherland)': False, 'contains(stumbling)': False, 'contains(around)': False, 'contains(drunkenly)': False, 'contains(hey)': False, 'contains(let)': False, 'contains(some)': False, 'contains(robots)': False, 'contains(acting)': False, 'contains(below)': False, 'contains(average)': False, 'contains(likes)': False, 'contains(re)': True, 'contains(likely)': False, 'contains(work)': False, 'contains(halloween)': False, 'contains(h20)': False, 'contains(wasted)': False, 'contains(real)': False, 'contains(star)': False, 'contains(stan)': False, 'contains(winston)': False, 'contains(robot)': False, 'contains(design)': False, 'contains(schnazzy)': False, 'contains(cgi)': False, 'contains(occasional)': False, 'contains(shot)': False, 'contains(picking)': False, 'contains(brain)': False, 'contains(if)': True, 'contains(body)': False, 'contains(parts)': False, 'contains(turn)': False, 'contains(otherwise)': False, 'contains(much)': False, 'contains(sunken)': False, 'contains(jaded)': False, 'contains(viewer)': False, 'contains(thankful)': False, 'contains(invention)': False, 'contains(timex)': False, 'contains(indiglo)': False, 'contains(based)': False, 'contains(late)': False, 'contains(1960)': False, 'contains(television)': False, 'contains(show)': False, 'contains(name)': False, 'contains(mod)': False, 'contains(squad)': False, 'contains(tells)': False, 'contains(tale)': False, 'contains(three)': False, 'contains(reformed)': False, 'contains(criminals)': False, 'contains(under)': False, 'contains(employ)': False, 'contains(police)': False, 'contains(undercover)': True, 'contains(however)': True, 'contains(wrong)': True, 'contains(evidence)': False, 'contains(gets)': True, 'contains(stolen)': False, 'contains(immediately)': False, 'contains(suspicion)': False, 'contains(ads)': False, 'contains(cuts)': False, 'contains(claire)': False, 'contains(dane)': False, 'contains(nice)': False, 'contains(hair)': False, 'contains(cute)': False, 'contains(outfits)': False, 'contains(car)': False, 'contains(chases)': False, 'contains(stuff)': False, 'contains(blowing)': False, 'contains(sounds)': False, 'contains(first)': False, 'contains(fifteen)': False, 'contains(quickly)': False, 'contains(becomes)': False, 'contains(apparent)': False, 'contains(certainly)': False, 'contains(slick)': False, 'contains(looking)': False, 'contains(complete)': False, 'contains(costumes)': False, 'contains(isn)': False, 'contains(enough)': False, 'contains(best)': True, 'contains(described)': False, 'contains(cross)': False, 'contains(between)': True, 'contains(hour)': False, 'contains(long)': False, 'contains(cop)': False, 'contains(stretched)': False, 'contains(span)': False, 'contains(single)': False, 'contains(clich)': False, 'contains(matter)': False, 'contains(elements)': False, 'contains(recycled)': False, 'contains(everything)': True, 'contains(already)': False, 'contains(seen)': False, 'contains(nothing)': False, 'contains(spectacular)': False, 'contains(sometimes)': False, 'contains(bordering)': False, 'contains(wooden)': False, 'contains(danes)': False, 'contains(omar)': False, 'contains(epps)': False, 'contains(deliver)': False, 'contains(their)': False, 'contains(lines)': False, 'contains(bored)': False, 'contains(transfers)': False, 'contains(onto)': False, 'contains(escape)': False, 'contains(relatively)': False, 'contains(unscathed)': False, 'contains(giovanni)': False, 'contains(ribisi)': False, 'contains(plays)': False, 'contains(resident)': False, 'contains(crazy)': False, 'contains(man)': False, 'contains(ultimately)': False, 'contains(being)': False, 'contains(worth)': True, 'contains(watching)': False, 'contains(unfortunately)': False, 'contains(save)': False, 'contains(convoluted)': False, 'contains(apart)': False, 'contains(occupying)': False, 'contains(screen)': True, 'contains(young)': False, 'contains(cast)': False, 'contains(clothes)': False, 'contains(hip)': False, 'contains(soundtrack)': False, 'contains(appears)': False, 'contains(geared)': False, 'contains(towards)': False, 'contains(teenage)': False, 'contains(mindset)': False, 'contains(r)': False, 'contains(rating)': False, 'contains(content)': False, 'contains(justify)': False, 'contains(juvenile)': False, 'contains(older)': False, 'contains(information)': False, 'contains(literally)': False, 'contains(spoon)': False, 'contains(hard)': False, 'contains(instead)': False, 'contains(telling)': False, 'contains(dialogue)': False, 'contains(poorly)': False, 'contains(written)': False, 'contains(extremely)': False, 'contains(predictable)': False, 'contains(progresses)': False, 'contains(won)': False, 'contains(care)': False, 'contains(heroes)': False, 'contains(any)': False, 'contains(jeopardy)': False, 'contains(ll)': False, 'contains(aren)': False, 'contains(basing)': False, 'contains(nobody)': False, 'contains(remembers)': False, 'contains(questionable)': False, 'contains(wisdom)': False, 'contains(especially)': True, 'contains(considers)': False, 'contains(target)': False, 'contains(fact)': False, 'contains(number)': False, 'contains(memorable)': False, 'contains(can)': False, 'contains(counted)': False, 'contains(hand)': False, 'contains(missing)': False, 'contains(finger)': False, 'contains(times)': False, 'contains(checked)': False, 'contains(six)': False, 'contains(clear)': False, 'contains(indication)': False, 'contains(them)': True, 'contains(than)': False, 'contains(cash)': False, 'contains(spending)': False, 'contains(dollar)': False, 'contains(judging)': False, 'contains(rash)': False, 'contains(awful)': False, 'contains(seeing)': True, 'contains(avoid)': False, 'contains(at)': False, 'contains(costs)': False, 'contains(quest)': False, 'contains(camelot)': False, 'contains(warner)': False, 'contains(bros)': False, 'contains(feature)': False, 'contains(length)': False, 'contains(fully)': False, 'contains(animated)': False, 'contains(steal)': False, 'contains(clout)': False, 'contains(disney)': False, 'contains(cartoon)': False, 'contains(empire)': False, 'contains(mouse)': False, 'contains(reason)': False, 'contains(worried)': False, 'contains(other)': True, 'contains(recent)': False, 'contains(challenger)': False, 'contains(throne)': False, 'contains(last)': False, 'contains(fall)': False, 'contains(promising)': False, 'contains(flawed)': False, 'contains(20th)': False, 'contains(century)': False, 'contains(fox)': False, 'contains(anastasia)': False, 'contains(hercules)': False, 'contains(lively)': False, 'contains(colorful)': False, 'contains(palate)': False, 'contains(had)': False, 'contains(beat)': False, 'contains(hands)': False, 'contains(crown)': False, 'contains(1997)': False, 'contains(piece)': False, 'contains(animation)': False, 'contains(year)': False, 'contains(contest)': False, 'contains(arrival)': False, 'contains(magic)': False, 'contains(kingdom)': False, 'contains(mediocre)': False, 'contains(--)': True, 'contains(d)': False, 'contains(pocahontas)': False, 'contains(those)': False, 'contains(keeping)': False, 'contains(score)': False, 'contains(nearly)': False, 'contains(dull)': False, 'contains(revolves)': False, 'contains(adventures)': False, 'contains(free)': False, 'contains(spirited)': False, 'contains(kayley)': False, 'contains(voiced)': False, 'contains(jessalyn)': False, 'contains(gilsig)': False, 'contains(early)': True, 'contains(daughter)': False, 'contains(belated)': False, 'contains(knight)': False, 'contains(king)': False, 'contains(arthur)': False, 'contains(round)': False, 'contains(table)': False, 'contains(dream)': False, 'contains(follow)': False, 'contains(father)': False, 'contains(footsteps)': False, 'contains(she)': True, 'contains(chance)': False, 'contains(evil)': False, 'contains(warlord)': False, 'contains(ruber)': False, 'contains(gary)': False, 'contains(oldman)': False, 'contains(ex)': False, 'contains(gone)': False, 'contains(steals)': False, 'contains(magical)': False, 'contains(sword)': False, 'contains(excalibur)': False, 'contains(accidentally)': False, 'contains(loses)': False, 'contains(dangerous)': True, 'contains(booby)': False, 'contains(trapped)': False, 'contains(forest)': False, 'contains(help)': True, 'contains(hunky)': False, 'contains(blind)': False, 'contains(timberland)': False, 'contains(dweller)': False, 'contains(garrett)': False, 'contains(carey)': False, 'contains(elwes)': False, 'contains(headed)': False, 'contains(dragon)': False, 'contains(eric)': False, 'contains(idle)': False, 'contains(rickles)': False, 'contains(arguing)': False, 'contains(itself)': False, 'contains(able)': False, 'contains(medieval)': False, 'contains(sexist)': False, 'contains(prove)': False, 'contains(fighter)': False, 'contains(side)': False, 'contains(pure)': False, 'contains(showmanship)': False, 'contains(essential)': False, 'contains(element)': False, 'contains(expected)': False, 'contains(climb)': False, 'contains(high)': False, 'contains(ranks)': False, 'contains(differentiates)': False, 'contains(something)': False, 'contains(saturday)': False, 'contains(morning)': False, 'contains(subpar)': False, 'contains(instantly)': False, 'contains(forgettable)': False, 'contains(songs)': False, 'contains(integrated)': False, 'contains(computerized)': False, 'contains(footage)': False, 'contains(compare)': False, 'contains(run)': False, 'contains(angry)': False, 'contains(ogre)': False, 'contains(herc)': False, 'contains(battle)': False, 'contains(hydra)': False, 'contains(rest)': False, 'contains(case)': False, 'contains(stink)': False, 'contains(none)': False, 'contains(remotely)': False, 'contains(interesting)': False, 'contains(race)': False, 'contains(bland)': False, 'contains(end)': False, 'contains(tie)': False, 'contains(win)': False, 'contains(comedy)': True, 'contains(shtick)': False, 'contains(awfully)': False, 'contains(cloying)': False, 'contains(least)': True, 'contains(signs)': False, 'contains(pulse)': False, 'contains(fans)': False, \"contains(-')\": False, 'contains(90s)': False, 'contains(tgif)': False, 'contains(will)': True, 'contains(thrilled)': False, 'contains(jaleel)': False, 'contains(urkel)': False, 'contains(white)': False, 'contains(bronson)': False, 'contains(balki)': False, 'contains(pinchot)': False, 'contains(sharing)': False, 'contains(nicely)': False, 'contains(realized)': False, 'contains(though)': False, 'contains(m)': False, 'contains(loss)': False, 'contains(recall)': False, 'contains(specific)': False, 'contains(providing)': False, 'contains(voice)': False, 'contains(talent)': False, 'contains(enthusiastic)': False, 'contains(paired)': False, 'contains(singers)': False, 'contains(sound)': False, 'contains(musical)': False, 'contains(moments)': False, 'contains(jane)': False, 'contains(seymour)': False, 'contains(celine)': False, 'contains(dion)': False, 'contains(must)': False, 'contains(strain)': False, 'contains(through)': False, 'contains(aside)': False, 'contains(children)': False, 'contains(probably)': False, 'contains(adults)': False, 'contains(grievous)': False, 'contains(error)': False, 'contains(lack)': False, 'contains(personality)': False, 'contains(learn)': False, 'contains(goes)': False, 'contains(synopsis)': False, 'contains(mentally)': False, 'contains(unstable)': False, 'contains(undergoing)': False, 'contains(psychotherapy)': False, 'contains(saves)': False, 'contains(boy)': False, 'contains(potentially)': False, 'contains(fatal)': False, 'contains(falls)': False, 'contains(love)': False, 'contains(mother)': False, 'contains(fledgling)': False, 'contains(restauranteur)': False, 'contains(unsuccessfully)': False, 'contains(attempting)': False, 'contains(gain)': False, 'contains(woman)': True, 'contains(favor)': False, 'contains(takes)': False, 'contains(pictures)': False, 'contains(kills)': False, 'contains(comments)': True, 'contains(stalked)': False, 'contains(yet)': False, 'contains(seemingly)': False, 'contains(endless)': True, 'contains(string)': False, 'contains(spurned)': False, 'contains(psychos)': False, 'contains(getting)': True, 'contains(revenge)': False, 'contains(type)': False, 'contains(stable)': False, 'contains(category)': False, 'contains(1990s)': False, 'contains(industry)': False, 'contains(theatrical)': False, 'contains(direct)': False, 'contains(proliferation)': False, 'contains(may)': False, 'contains(due)': False, 'contains(typically)': False, 'contains(inexpensive)': False, 'contains(produce)': False, 'contains(special)': False, 'contains(effects)': False, 'contains(stars)': False, 'contains(serve)': False, 'contains(vehicles)': False, 'contains(nudity)': False, 'contains(allowing)': False, 'contains(frequent)': False, 'contains(night)': False, 'contains(cable)': False, 'contains(wavers)': False, 'contains(slightly)': False, 'contains(norm)': False, 'contains(respect)': False, 'contains(psycho)': False, 'contains(never)': True, 'contains(affair)': False, 'contains(;)': False, 'contains(contrary)': False, 'contains(rejected)': False, 'contains(rather)': False, 'contains(lover)': False, 'contains(wife)': True, 'contains(husband)': False, 'contains(entry)': False, 'contains(doomed)': False, 'contains(collect)': False, 'contains(dust)': False, 'contains(viewed)': False, 'contains(midnight)': False, 'contains(provide)': False, 'contains(suspense)': False, 'contains(sets)': False, 'contains(interspersed)': False, 'contains(opening)': False, 'contains(credits)': False, 'contains(instance)': False, 'contains(serious)': False, 'contains(sounding)': False, 'contains(narrator)': False, 'contains(spouts)': False, 'contains(statistics)': False, 'contains(stalkers)': False, 'contains(ponders)': False, 'contains(cause)': False, 'contains(stalk)': False, 'contains(implicitly)': False, 'contains(implied)': False, 'contains(men)': False, 'contains(shown)': False, 'contains(snapshot)': False, 'contains(actor)': False, 'contains(jay)': False, 'contains(underwood)': False, 'contains(states)': False, 'contains(daryl)': False, 'contains(gleason)': False, 'contains(stalker)': False, 'contains(brooke)': False, 'contains(daniels)': False, 'contains(meant)': False, 'contains(called)': False, 'contains(guesswork)': False, 'contains(required)': False, 'contains(proceeds)': False, 'contains(begins)': False, 'contains(obvious)': False, 'contains(sequence)': False, 'contains(contrived)': False, 'contains(quite)': False, 'contains(brings)': False, 'contains(victim)': False, 'contains(together)': False, 'contains(obsesses)': False, 'contains(follows)': False, 'contains(tries)': True, 'contains(woo)': False, 'contains(plans)': False, 'contains(become)': False, 'contains(desperate)': False, 'contains(elaborate)': False, 'contains(include)': False, 'contains(cliche)': False, 'contains(murdered)': False, 'contains(pet)': False, 'contains(require)': False, 'contains(found)': False, 'contains(exception)': False, 'contains(cat)': False, 'contains(shower)': False, 'contains(events)': False, 'contains(lead)': True, 'contains(inevitable)': False, 'contains(showdown)': False, 'contains(survives)': False, 'contains(invariably)': False, 'contains(conclusion)': False, 'contains(turkey)': False, 'contains(uniformly)': False, 'contains(adequate)': False, 'contains(anything)': False, 'contains(home)': False, 'contains(either)': False, 'contains(turns)': False, 'contains(toward)': False, 'contains(melodrama)': False, 'contains(overdoes)': False, 'contains(words)': False, 'contains(manages)': False, 'contains(creepy)': False, 'contains(pass)': False, 'contains(demands)': False, 'contains(maryam)': False, 'contains(abo)': False, 'contains(close)': False, 'contains(played)': True, 'contains(bond)': False, 'contains(chick)': False, 'contains(living)': False, 'contains(daylights)': False, 'contains(equally)': False, 'contains(title)': False, 'contains(ditzy)': False, 'contains(strong)': False, 'contains(independent)': False, 'contains(business)': False, 'contains(owner)': False, 'contains(needs)': False, 'contains(proceed)': False, 'contains(example)': False, 'contains(suspicions)': False, 'contains(ensure)': False, 'contains(use)': False, 'contains(excuse)': False, 'contains(decides)': False, 'contains(return)': False, 'contains(toolbox)': False, 'contains(left)': False, 'contains(place)': True, 'contains(house)': False, 'contains(leave)': False, 'contains(door)': False, 'contains(answers)': False, 'contains(opens)': False, 'contains(wanders)': False, 'contains(returns)': False, 'contains(enters)': False, 'contains(our)': False, 'contains(heroine)': False, 'contains(danger)': False, 'contains(somehow)': False, 'contains(parked)': False, 'contains(front)': False, 'contains(right)': False, 'contains(oblivious)': False, 'contains(presence)': False, 'contains(inside)': False, 'contains(whole)': False, 'contains(episode)': False, 'contains(places)': False, 'contains(incredible)': False, 'contains(suspension)': False, 'contains(disbelief)': False, 'contains(questions)': False, 'contains(validity)': False, 'contains(intelligence)': False, 'contains(receives)': False, 'contains(highly)': False, 'contains(derivative)': False, 'contains(somewhat)': False, 'contains(boring)': False, 'contains(cannot)': False, 'contains(watched)': False, 'contains(rated)': False, 'contains(mostly)': False, 'contains(several)': False, 'contains(murder)': False, 'contains(brief)': True, 'contains(strip)': False, 'contains(bar)': False, 'contains(offensive)': False, 'contains(many)': True, 'contains(thrillers)': False, 'contains(mood)': False, 'contains(stake)': False, 'contains(else)': False, 'contains(capsule)': True, 'contains(2176)': False, 'contains(planet)': False, 'contains(mars)': False, 'contains(taking)': False, 'contains(custody)': False, 'contains(accused)': False, 'contains(murderer)': False, 'contains(face)': False, 'contains(menace)': False, 'contains(lot)': False, 'contains(fighting)': False, 'contains(john)': False, 'contains(carpenter)': False, 'contains(reprises)': False, 'contains(ideas)': False, 'contains(previous)': False, 'contains(assault)': False, 'contains(precinct)': False, 'contains(13)': False, 'contains(homage)': False, 'contains(himself)': False, 'contains(0)': False, 'contains(+)': False, 'contains(believes)': False, 'contains(fight)': True, 'contains(horrible)': False, 'contains(writer)': False, 'contains(supposedly)': False, 'contains(expert)': False, 'contains(mistake)': False, 'contains(ghosts)': False, 'contains(drawn)': False, 'contains(humans)': False, 'contains(surprisingly)': False, 'contains(low)': False, 'contains(powered)': False, 'contains(alien)': False, 'contains(addition)': False, 'contains(anybody)': False, 'contains(made)': False, 'contains(grounds)': False, 'contains(sue)': False, 'contains(chock)': False, 'contains(full)': False, 'contains(pieces)': False, 'contains(prince)': False, 'contains(darkness)': False, 'contains(surprising)': False, 'contains(managed)': False, 'contains(fit)': False, 'contains(admittedly)': False, 'contains(novel)': False, 'contains(science)': False, 'contains(fiction)': False, 'contains(experience)': False, 'contains(terraformed)': False, 'contains(walk)': False, 'contains(surface)': False, 'contains(without)': False, 'contains(breathing)': False, 'contains(gear)': False, 'contains(budget)': False, 'contains(mentioned)': False, 'contains(gravity)': False, 'contains(increased)': False, 'contains(earth)': False, 'contains(easier)': False, 'contains(society)': False, 'contains(changed)': False, 'contains(advanced)': False, 'contains(culture)': False, 'contains(women)': False, 'contains(positions)': False, 'contains(control)': False, 'contains(view)': False, 'contains(stagnated)': False, 'contains(female)': False, 'contains(beyond)': False, 'contains(minor)': False, 'contains(technological)': False, 'contains(advances)': False, 'contains(less)': False, 'contains(175)': False, 'contains(expect)': False, 'contains(change)': False, 'contains(ten)': False, 'contains(basic)': False, 'contains(common)': False, 'contains(except)': False, 'contains(yes)': False, 'contains(replaced)': False, 'contains(tacky)': False, 'contains(rundown)': False, 'contains(martian)': False, 'contains(mining)': False, 'contains(colony)': False, 'contains(having)': False, 'contains(criminal)': False, 'contains(napolean)': False, 'contains(wilson)': False, 'contains(desolation)': False, 'contains(williams)': False, 'contains(facing)': False, 'contains(hoodlums)': False, 'contains(automatic)': False, 'contains(weapons)': False, 'contains(nature)': False, 'contains(behave)': False, 'contains(manner)': False, 'contains(essentially)': False, 'contains(human)': False, 'contains(savages)': False, 'contains(lapse)': False, 'contains(imagination)': False, 'contains(told)': False, 'contains(flashback)': False, 'contains(entirely)': False, 'contains(filmed)': False, 'contains(almost)': False, 'contains(tones)': False, 'contains(red)': False, 'contains(yellow)': False, 'contains(black)': False, 'contains(powerful)': False, 'contains(scene)': True, 'contains(train)': True, 'contains(rushing)': False, 'contains(heavy)': False, 'contains(sadly)': False, 'contains(buildup)': False, 'contains(terror)': False, 'contains(creates)': False, 'contains(looks)': True, 'contains(fugitive)': False, 'contains(wannabes)': False, 'contains(rock)': False, 'contains(band)': False, 'contains(kiss)': False, 'contains(building)': False, 'contains(bunch)': False, 'contains(sudden)': False, 'contains(jump)': False, 'contains(sucker)': False, 'contains(thinking)': False, 'contains(scary)': False, 'contains(happening)': False, 'contains(standard)': False, 'contains(haunted)': False, 'contains(shock)': False, 'contains(great)': True, 'contains(newer)': False, 'contains(unimpressive)': False, 'contains(digital)': False, 'contains(decapitations)': False, 'contains(fights)': False, 'contains(short)': False, 'contains(stretch)': False, 'contains(release)': False, 'contains(mission)': False, 'contains(panned)': False, 'contains(reviewers)': False, 'contains(better)': False, 'contains(rate)': False, 'contains(scale)': False, 'contains(following)': False, 'contains(showed)': False, 'contains(liked)': False, 'contains(moderately)': False, 'contains(classic)': False, 'contains(comment)': False, 'contains(twice)': False, 'contains(ask)': False, 'contains(yourself)': False, 'contains(8mm)': False, 'contains(eight)': True, 'contains(millimeter)': False, 'contains(wholesome)': False, 'contains(surveillance)': False, 'contains(sight)': False, 'contains(values)': False, 'contains(becoming)': False, 'contains(enmeshed)': False, 'contains(seedy)': False, 'contains(sleazy)': False, 'contains(underworld)': False, 'contains(hardcore)': False, 'contains(pornography)': False, 'contains(bubbling)': False, 'contains(beneath)': False, 'contains(town)': False, 'contains(americana)': False, 'contains(sordid)': False, 'contains(sick)': False, 'contains(depraved)': False, 'contains(necessarily)': False, 'contains(stop)': True, 'contains(order)': False, 'contains(satisfy)': False, 'contains(twisted)': False, 'contains(desires)': False, 'contains(position)': False, 'contains(influence)': False, 'contains(kinds)': False, 'contains(demented)': False, 'contains(talking)': False, 'contains(snuff)': False, 'contains(supposed)': False, 'contains(documentaries)': False, 'contains(victims)': False, 'contains(brutalized)': False, 'contains(killed)': False, 'contains(camera)': False, 'contains(joel)': False, 'contains(schumacher)': False, 'contains(credit)': False, 'contains(batman)': False, 'contains(robin)': False, 'contains(kill)': False, 'contains(forever)': False, 'contains(client)': False, 'contains(thirds)': False, 'contains(unwind)': False, 'contains(fairly)': True, 'contains(conventional)': False, 'contains(persons)': False, 'contains(drama)': False, 'contains(albeit)': False, 'contains(particularly)': False, 'contains(unsavory)': False, 'contains(core)': False, 'contains(threatening)': False, 'contains(along)': True, 'contains(explodes)': False, 'contains(violence)': False, 'contains(think)': False, 'contains(finally)': False, 'contains(tags)': False, 'contains(ridiculous)': False, 'contains(self)': False, 'contains(righteous)': False, 'contains(finale)': False, 'contains(drags)': False, 'contains(unpleasant)': False, 'contains(trust)': False, 'contains(waste)': False, 'contains(hours)': False, 'contains(nicolas)': False, 'contains(snake)': False, 'contains(eyes)': False, 'contains(cage)': False, 'contains(private)': False, 'contains(investigator)': False, 'contains(tom)': False, 'contains(welles)': False, 'contains(hired)': False, 'contains(wealthy)': False, 'contains(philadelphia)': False, 'contains(widow)': False, 'contains(determine)': False, 'contains(whether)': False, 'contains(reel)': False, 'contains(safe)': False, 'contains(documents)': False, 'contains(girl)': False, 'contains(assignment)': True, 'contains(factly)': False, 'contains(puzzle)': False, 'contains(neatly)': False, 'contains(specialized)': False, 'contains(skills)': False, 'contains(training)': False, 'contains(easy)': False, 'contains(cops)': False, 'contains(toilet)': False, 'contains(tanks)': False, 'contains(clues)': False, 'contains(deeper)': False, 'contains(digs)': False, 'contains(investigation)': False, 'contains(obsessed)': False, 'contains(george)': False, 'contains(c)': False, 'contains(scott)': False, 'contains(paul)': False, 'contains(schrader)': False, 'contains(occasionally)': False, 'contains(flickering)': False, 'contains(whirs)': False, 'contains(sprockets)': False, 'contains(winding)': False, 'contains(projector)': False, 'contains(reminding)': False, 'contains(task)': False, 'contains(hints)': False, 'contains(toll)': False, 'contains(lovely)': False, 'contains(catherine)': False, 'contains(keener)': False, 'contains(frustrated)': False, 'contains(cleveland)': False, 'contains(ugly)': False, 'contains(split)': False, 'contains(level)': False, 'contains(harrisburg)': False, 'contains(pa)': False, 'contains(condemn)': False, 'contains(condone)': False, 'contains(subject)': False, 'contains(exploits)': False, 'contains(irony)': False, 'contains(seven)': False, 'contains(scribe)': False, 'contains(andrew)': False, 'contains(kevin)': True, 'contains(walker)': False, 'contains(vision)': False, 'contains(lane)': False, 'contains(limited)': False, 'contains(hollywood)': False, 'contains(product)': False, 'contains(snippets)': False, 'contains(covering)': False, 'contains(later)': False, 'contains(joaquin)': False, 'contains(phoenix)': False, 'contains(far)': False, 'contains(adult)': False, 'contains(bookstore)': False, 'contains(flunky)': False, 'contains(max)': False, 'contains(california)': False, 'contains(cover)': False, 'contains(horrid)': False, 'contains(screened)': False, 'contains(familiar)': False, 'contains(revelation)': False, 'contains(sexual)': False, 'contains(deviants)': False, 'contains(indeed)': False, 'contains(monsters)': False, 'contains(everyday)': False, 'contains(neither)': False, 'contains(super)': False, 'contains(nor)': False, 'contains(shocking)': False, 'contains(banality)': False, 'contains(exactly)': False, 'contains(felt)': False, 'contains(weren)': False, 'contains(nine)': False, 'contains(laughs)': False, 'contains(months)': False, 'contains(terrible)': False, 'contains(mr)': False, 'contains(hugh)': False, 'contains(grant)': False, 'contains(huge)': False, 'contains(dork)': False, 'contains(oral)': False, 'contains(sex)': False, 'contains(prostitution)': False, 'contains(referring)': False, 'contains(bugs)': False, 'contains(annoying)': False, 'contains(adam)': False, 'contains(sandler)': False, 'contains(jim)': False, 'contains(carrey)': False, 'contains(eye)': False, 'contains(flutters)': False, 'contains(nervous)': False, 'contains(smiles)': False, 'contains(slapstick)': False, 'contains(fistfight)': False, 'contains(delivery)': False, 'contains(room)': False, 'contains(culminating)': False, 'contains(joan)': False, 'contains(cusack)': False, 'contains(lap)': False, 'contains(paid)': False, 'contains($)': False, 'contains(60)': False, 'contains(included)': False, 'contains(obscene)': False, 'contains(double)': False, 'contains(entendres)': False, 'contains(obstetrician)': False, 'contains(pregnant)': False, 'contains(pussy)': False, 'contains(size)': False, 'contains(hairs)': False, 'contains(coat)': False, 'contains(nonetheless)': False, 'contains(exchange)': False, 'contains(cookie)': False, 'contains(cutter)': False, 'contains(originality)': False, 'contains(humor)': False, 'contains(successful)': False, 'contains(child)': False, 'contains(psychiatrist)': False, 'contains(psychologist)': False, 'contains(scriptwriters)': False, 'contains(could)': False, 'contains(inject)': False, 'contains(unfunny)': False, 'contains(kid)': False, 'contains(dad)': False, 'contains(asshole)': False, 'contains(eyelashes)': False, 'contains(offers)': False, 'contains(smile)': False, 'contains(responds)': False, 'contains(english)': False, 'contains(accent)': False, 'contains(attitude)': False, 'contains(possibly)': False, 'contains(_huge_)': False, 'contains(beside)': False, 'contains(includes)': False, 'contains(needlessly)': False, 'contains(stupid)': False, 'contains(jokes)': False, 'contains(olds)': False, 'contains(everyone)': False, 'contains(shakes)': False, 'contains(anyway)': False, 'contains(finds)': False, 'contains(usual)': False, 'contains(reaction)': False, 'contains(fluttered)': False, 'contains(paves)': False, 'contains(possible)': False, 'contains(pregnancy)': False, 'contains(birth)': False, 'contains(gag)': False, 'contains(book)': False, 'contains(friend)': False, 'contains(arnold)': True, 'contains(provides)': False, 'contains(cacophonous)': False, 'contains(funny)': True, 'contains(beats)': False, 'contains(costumed)': False, 'contains(arnie)': False, 'contains(dinosaur)': False, 'contains(draw)': False, 'contains(parallels)': False, 'contains(toy)': False, 'contains(store)': False, 'contains(jeff)': False, 'contains(goldblum)': False, 'contains(hid)': False, 'contains(dreadful)': False, 'contains(hideaway)': False, 'contains(artist)': False, 'contains(fear)': False, 'contains(simultaneous)': False, 'contains(longing)': False, 'contains(commitment)': False, 'contains(doctor)': False, 'contains(recently)': False, 'contains(switch)': False, 'contains(veterinary)': False, 'contains(medicine)': False, 'contains(obstetrics)': False, 'contains(joke)': False, 'contains(old)': False, 'contains(foreign)': False, 'contains(guy)': True, 'contains(mispronounces)': False, 'contains(stereotype)': False, 'contains(say)': False, 'contains(yakov)': False, 'contains(smirnov)': False, 'contains(favorite)': False, 'contains(vodka)': False, 'contains(hence)': False, 'contains(take)': False, 'contains(volvo)': False, 'contains(nasty)': False, 'contains(unamusing)': False, 'contains(heads)': False, 'contains(simultaneously)': False, 'contains(groan)': False, 'contains(failure)': False, 'contains(loud)': False, 'contains(failed)': False, 'contains(uninspired)': False, 'contains(lunacy)': False, 'contains(sunset)': False, 'contains(boulevard)': False, 'contains(arrest)': False, 'contains(please)': False, 'contains(caught)': False, 'contains(pants)': False, 'contains(bring)': False, 'contains(theaters)': False, 'contains(faces)': False, 'contains(90)': False, 'contains(forced)': False, 'contains(unauthentic)': False, 'contains(anyone)': False, 'contains(q)': False, 'contains(80)': False, 'contains(sorry)': False, 'contains(money)': False, 'contains(unfulfilled)': False, 'contains(desire)': False, 'contains(spend)': False, 'contains(bucks)': False, 'contains(call)': False, 'contains(road)': False, 'contains(trip)': False, 'contains(walking)': False, 'contains(wounded)': False, 'contains(stellan)': False, 'contains(skarsg)': False, 'contains(rd)': False, 'contains(convincingly)': False, 'contains(zombified)': False, 'contains(drunken)': False, 'contains(loser)': False, 'contains(difficult)': True, 'contains(smelly)': False, 'contains(boozed)': False, 'contains(reliable)': False, 'contains(swedish)': False, 'contains(adds)': False, 'contains(depth)': False, 'contains(significance)': False, 'contains(plodding)': False, 'contains(aberdeen)': False, 'contains(sentimental)': False, 'contains(painfully)': False, 'contains(mundane)': False, 'contains(european)': False, 'contains(playwright)': False, 'contains(august)': False, 'contains(strindberg)': False, 'contains(built)': False, 'contains(career)': False, 'contains(families)': False, 'contains(relationships)': False, 'contains(paralyzed)': False, 'contains(secrets)': False, 'contains(unable)': False, 'contains(express)': False, 'contains(longings)': False, 'contains(accurate)': False, 'contains(reflection)': False, 'contains(strives)': False, 'contains(focusing)': False, 'contains(pairing)': False, 'contains(alcoholic)': False, 'contains(tomas)': False, 'contains(alienated)': False, 'contains(openly)': False, 'contains(hostile)': False, 'contains(yuppie)': False, 'contains(kaisa)': False, 'contains(lena)': False, 'contains(headey)': False, 'contains(gossip)': False, 'contains(haven)': False, 'contains(spoken)': False, 'contains(wouldn)': False, 'contains(norway)': False, 'contains(scotland)': False, 'contains(automobile)': False, 'contains(charlotte)': False, 'contains(rampling)': False, 'contains(sand)': False, 'contains(rotting)': False, 'contains(hospital)': False, 'contains(bed)': False, 'contains(cancer)': False, 'contains(soap)': False, 'contains(opera)': False, 'contains(twist)': False, 'contains(days)': False, 'contains(live)': False, 'contains(blitzed)': False, 'contains(step)': False, 'contains(foot)': False, 'contains(plane)': False, 'contains(hits)': False, 'contains(open)': False, 'contains(loathing)': False, 'contains(each)': True, 'contains(periodic)': False, 'contains(stops)': True, 'contains(puke)': False, 'contains(dashboard)': False, 'contains(whenever)': False, 'contains(muttering)': False, 'contains(rotten)': False, 'contains(turned)': False, 'contains(sloshed)': False, 'contains(viewpoint)': False, 'contains(recognizes)': False, 'contains(apple)': False, 'contains(hasn)': False, 'contains(fallen)': False, 'contains(tree)': False, 'contains(nosebleeds)': False, 'contains(snorting)': False, 'contains(coke)': False, 'contains(sabotages)': False, 'contains(personal)': False, 'contains(indifference)': False, 'contains(restrain)': False, 'contains(vindictive)': False, 'contains(temper)': False, 'contains(ain)': False, 'contains(pair)': False, 'contains(true)': False, 'contains(notes)': False, 'contains(unspoken)': False, 'contains(familial)': False, 'contains(empathy)': False, 'contains(note)': False, 'contains(repetitively)': False, 'contains(bitchy)': False, 'contains(screenwriters)': False, 'contains(kristin)': False, 'contains(amundsen)': False, 'contains(hans)': False, 'contains(petter)': False, 'contains(moland)': False, 'contains(fabricate)': False, 'contains(series)': True, 'contains(contrivances)': False, 'contains(propel)': False, 'contains(forward)': False, 'contains(roving)': False, 'contains(hooligans)': False, 'contains(drunks)': False, 'contains(nosy)': False, 'contains(flat)': False, 'contains(tires)': False, 'contains(figure)': False, 'contains(schematic)': False, 'contains(convenient)': False, 'contains(narrative)': False, 'contains(reach)': False, 'contains(unveil)': False, 'contains(dark)': False, 'contains(past)': False, 'contains(simplistic)': False, 'contains(devices)': False, 'contains(trivialize)': False, 'contains(conflict)': False, 'contains(mainstays)': False, 'contains(wannabe)': False, 'contains(exists)': False, 'contains(purely)': False, 'contains(sake)': False, 'contains(weak)': False, 'contains(unimaginative)': False, 'contains(casting)': False, 'contains(thwarts)': False, 'contains(pivotal)': False, 'contains(role)': False, 'contains(were)': False, 'contains(stronger)': False, 'contains(actress)': False, 'contains(perhaps)': False, 'contains(coast)': True, 'contains(performances)': False, 'contains(moody)': False, 'contains(haunting)': False, 'contains(cinematography)': False, 'contains(rendering)': False, 'contains(pastoral)': False, 'contains(ghost)': False, 'contains(reference)': False, 'contains(certain)': False, 'contains(superior)': False, 'contains(indie)': False, 'contains(intentional)': False, 'contains(busy)': False, 'contains(using)': False, 'contains(furrowed)': False, 'contains(brow)': False, 'contains(convey)': False, 'contains(twitch)': False, 'contains(insouciance)': False, 'contains(paying)': False, 'contains(attention)': False, 'contains(maybe)': False, 'contains(doing)': False, 'contains(reveal)': False, 'contains(worthwhile)': False, 'contains(earlier)': False, 'contains(released)': False, 'contains(2001)': False, 'contains(jonathan)': False, 'contains(nossiter)': False, 'contains(captivating)': False, 'contains(wonders)': False, 'contains(disturbed)': False, 'contains(parental)': False, 'contains(figures)': False, 'contains(bound)': False, 'contains(ceremonial)': False, 'contains(wedlock)': False, 'contains(differences)': False, 'contains(presented)': False, 'contains(significant)': False, 'contains(luminous)': False, 'contains(diva)': False, 'contains(preening)': False, 'contains(static)': False, 'contains(solid)': False, 'contains(performance)': False, 'contains(pathetic)': False, 'contains(drunk)': False, 'contains(emote)': False, 'contains(besides)': False, 'contains(catatonic)': False, 'contains(sorrow)': False, 'contains(genuine)': False, 'contains(ferocity)': False, 'contains(sexually)': False, 'contains(charged)': False, 'contains(frisson)': False, 'contains(during)': False, 'contains(understated)': False, 'contains(confrontations)': False, 'contains(suggest)': False, 'contains(gray)': False, 'contains(zone)': False, 'contains(complications)': False, 'contains(accompany)': False, 'contains(torn)': False, 'contains(romance)': False, 'contains(stifled)': False, 'contains(curiosity)': False, 'contains(thoroughly)': False, 'contains(explores)': False, 'contains(neurotic)': False, 'contains(territory)': False, 'contains(delving)': False, 'contains(americanization)': False, 'contains(greece)': False, 'contains(mysticism)': False, 'contains(illusion)': False, 'contains(deflect)': False, 'contains(pain)': False, 'contains(overloaded)': False, 'contains(willing)': False, 'contains(come)': False, 'contains(traditional)': False, 'contains(ambitious)': False, 'contains(sleepwalk)': False, 'contains(rhythms)': False, 'contains(timing)': False, 'contains(driven)': False, 'contains(stories)': False, 'contains(complexities)': False, 'contains(depressing)': False, 'contains(answer)': False, 'contains(lawrence)': False, 'contains(kasdan)': False, 'contains(trite)': False, 'contains(useful)': False, 'contains(grand)': False, 'contains(canyon)': False, 'contains(steve)': False, 'contains(martin)': False, 'contains(mogul)': False, 'contains(pronounces)': False, 'contains(riddles)': False, 'contains(answered)': False, 'contains(advice)': False, 'contains(heart)': False, 'contains(french)': False, 'contains(sees)': True, 'contains(parents)': False, 'contains(tim)': False, 'contains(roth)': False, 'contains(oops)': False, 'contains(vows)': False, 'contains(taught)': False, 'contains(musketeer)': False, 'contains(dude)': False, 'contains(used)': True, 'contains(fourteen)': False, 'contains(arrgh)': False, 'contains(swish)': False, 'contains(zzzzzzz)': False, 'contains(original)': False, 'contains(lacks)': False, 'contains(energy)': False, 'contains(next)': False, 'contains(hmmmm)': False, 'contains(justin)': False, 'contains(chambers)': False, 'contains(basically)': False, 'contains(uncharismatic)': False, 'contains(version)': False, 'contains(chris)': False, 'contains(o)': False, 'contains(donnell)': False, 'contains(range)': False, 'contains(mena)': False, 'contains(suvari)': False, 'contains(thora)': False, 'contains(birch)': False, 'contains(dungeons)': False, 'contains(dragons)': False, 'contains(miscast)': False, 'contains(deliveries)': False, 'contains(piss)': False, 'contains(poor)': False, 'contains(ms)': False, 'contains(fault)': False, 'contains(definitely)': False, 'contains(higher)': False, 'contains(semi)': False, 'contains(saving)': False, 'contains(grace)': False, 'contains(wise)': False, 'contains(irrepressible)': False, 'contains(once)': True, 'contains(thousand)': False, 'contains(god)': False, 'contains(beg)': False, 'contains(agent)': False, 'contains(marketplace)': False, 'contains(modern)': False, 'contains(day)': True, 'contains(roles)': False, 'contains(romantic)': False, 'contains(gunk)': False, 'contains(alright)': False, 'contains(yeah)': False, 'contains(yikes)': False, 'contains(notches)': False, 'contains(fellas)': False, 'contains(blares)': False, 'contains(ear)': False, 'contains(accentuate)': False, 'contains(annoy)': False, 'contains(important)': False, 'contains(behind)': False, 'contains(recognize)': False, 'contains(epic)': False, 'contains(fluffy)': False, 'contains(rehashed)': False, 'contains(cake)': False, 'contains(created)': False, 'contains(shrewd)': False, 'contains(advantage)': False, 'contains(kung)': True, 'contains(fu)': True, 'contains(phenomenon)': False, 'contains(test)': False, 'contains(dudes)': False, 'contains(keep)': False, 'contains(reading)': False, 'contains(editing)': False, 'contains(shoddy)': False, 'contains(banal)': False, 'contains(stilted)': False, 'contains(plentiful)': False, 'contains(top)': True, 'contains(horse)': False, 'contains(carriage)': False, 'contains(stand)': False, 'contains(opponent)': False, 'contains(scampering)': False, 'contains(cut)': False, 'contains(mouseketeer)': False, 'contains(rope)': False, 'contains(tower)': False, 'contains(jumping)': False, 'contains(chords)': False, 'contains(hanging)': False, 'contains(says)': False, 'contains(14)': False, 'contains(shirt)': False, 'contains(strayed)': False, 'contains(championing)': False, 'contains(fun)': True, 'contains(stretches)': False, 'contains(atrocious)': False, 'contains(lake)': False, 'contains(reminded)': False, 'contains(school)': False, 'contains(cringe)': False, 'contains(musketeers)': False, 'contains(fat)': False, 'contains(raison)': False, 'contains(etre)': False, 'contains(numbers)': False, 'contains(hoping)': False, 'contains(packed)': False, 'contains(stuntwork)': False, 'contains(promoted)': False, 'contains(trailer)': False, 'contains(major)': False, 'contains(swashbuckling)': False, 'contains(beginning)': False, 'contains(finishes)': False, 'contains(juggling)': False, 'contains(ladders)': False, 'contains(ladder)': True, 'contains(definite)': False, 'contains(keeper)': False, 'contains(regurgitated)': False, 'contains(crap)': False, 'contains(tell)': False, 'contains(deneuve)': False, 'contains(placed)': False, 'contains(hullo)': False, 'contains(barely)': False, 'contains(ugh)': False, 'contains(small)': False, 'contains(annoyed)': False, 'contains(trash)': False, 'contains(gang)': False, 'contains(vow)': False, 'contains(stay)': False, 'contains(thank)': False, 'contains(outlaws)': False, 'contains(5)': False, 'contains(crouching)': False, 'contains(tiger)': False, 'contains(hidden)': False, 'contains(matrix)': False, 'contains(replacement)': False, 'contains(killers)': False, 'contains(6)': False, 'contains(romeo)': False, 'contains(die)': False, 'contains(shanghai)': False, 'contains(noon)': False, 'contains(remembered)': False, 'contains(dr)': False, 'contains(hannibal)': False, 'contains(lecter)': False, 'contains(michael)': False, 'contains(mann)': False, 'contains(forensics)': False, 'contains(thriller)': False, 'contains(manhunter)': False, 'contains(scottish)': False, 'contains(brian)': False, 'contains(cox)': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEF4xJa2UDaG"
      },
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAN6KulQUDaH",
        "outputId": "d75063e9-90bd-4f15-a458-aae4414916cf"
      },
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpdfxN1qUDaH",
        "outputId": "30547f0e-a44b-42ac-a6c0-d3bce72b4f1d"
      },
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "    contains(schumacher) = True              neg : pos    =     11.8 : 1.0\n",
            "        contains(welles) = True              neg : pos    =      7.8 : 1.0\n",
            " contains(unimaginative) = True              neg : pos    =      7.8 : 1.0\n",
            "          contains(mena) = True              neg : pos    =      7.1 : 1.0\n",
            "     contains(atrocious) = True              neg : pos    =      7.1 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pFufi0FUDaH"
      },
      "source": [
        "### 6.1.4. Part-of-Speech Tagging\n",
        "\n",
        "(★ Assignment Remark)\n",
        "\n",
        "Exercise 5及び6で、我々は言葉の内部の構造を見て、単語の品詞タグを選択する正規表現タガーを構築しました。ただし、この正規表現タガーは手作りする必要がありました。代わりに、どのサフィックスが最も有益かを判断するために分類器をトレーニングできます。最も一般的なサフィックスが何であるかを調べることから始めましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyhX6maXUDaH",
        "outputId": "d2b95cdf-1656-4471-9e1e-77188c6453e5"
      },
      "source": [
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "suffix_fdist = nltk.FreqDist()\n",
        "for word in brown.words():\n",
        "    word = word.lower()\n",
        "    suffix_fdist[word[-1:]] += 1\n",
        "    suffix_fdist[word[-2:]] += 1\n",
        "    suffix_fdist[word[-3:]] += 1\n",
        "    \n",
        "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
        "print(common_suffixes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpfYiYirUDaH"
      },
      "source": [
        "これのSuffixから、特定の単語をチェックする特徴抽出関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBFq2UR8UDaI"
      },
      "source": [
        "def pos_features(word):\n",
        "    features = {}\n",
        "    for suffix in common_suffixes:\n",
        "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMJwUPZCUDaI"
      },
      "source": [
        "この特徴抽出関数はFilterとなり、データの一部のプロパティを強調し、他のプロパティを表示できないようにします。分類器は、入力にラベルを付ける方法を決定するときに、この強調されたプロパティのみを用いて分類します。\n",
        "\n",
        "続いて、この特徴分類器を用いて、Decision Tree分類器をトレーニングします。（Lesson 4で説明します）\n",
        "(注意: 非常にトレーニングに時間が掛かります。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BytDz6QhUDaI",
        "outputId": "3f86c484-5d1f-4fab-c60f-d377c5d9cca0"
      },
      "source": [
        "tagged_words = brown.tagged_words(categories='news')\n",
        "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))\n",
        "print(classifier.classify(pos_features('cats')))\n",
        "print(classifier.pseudocode(depth=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6270512182993535\n",
            "NNS\n",
            "if endswith(the) == False: \n",
            "  if endswith(,) == False: \n",
            "    if endswith(s) == False: \n",
            "      if endswith(.) == False: return '.'\n",
            "      if endswith(.) == True: return '.'\n",
            "    if endswith(s) == True: \n",
            "      if endswith(is) == False: return 'PP$'\n",
            "      if endswith(is) == True: return 'BEZ'\n",
            "  if endswith(,) == True: return ','\n",
            "if endswith(the) == True: return 'AT'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmFosXVUUDaI"
      },
      "source": [
        "Decision Treeモデルの優れた機能の1つは、それらの解釈が非常に簡単な場合が多いことです。NLTKに疑似コードとして出力するように指示することもできます。\n",
        "\n",
        "ここでは、単語がTheで終わるかどうかを確認します。その場合、ほぼ確実に決定子になります。  \n",
        "単語「the」は非常に一般的であるため、この「接尾辞」は決定ツリーで早期に使用されます。  \n",
        "次に、カンマで終わるかどうかを確認します。カンマで終わる場合、特別なタグ\",\"を受け取ります。  \n",
        "続いて、分類子は単語が「s」で終わるかどうかをチェックします。  \n",
        "その場合、PrepositionタグPP$を受け取る可能性が最も高く（特別なタグBEZを持つ「is」という単語でない限り）、そうでない場合は、あーてぃくyレーション（句読点 \"。\"でない限り）である可能性が最も高いです。  \n",
        "引数は、決定木の上部のみを表示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfZ7d5WtUDaI"
      },
      "source": [
        "### 1.5. Exploiting Context\n",
        "\n",
        "特徴抽出機能を強化することにより、この品詞タガーを変更して、単語の長さ、含まれる音節の数、またはその接頭辞など、他のさまざまな単語内部機能を活用できます。ただし、機能抽出プログラムが対象の単語を見る限り、その単語が表示されるコンテキストに依存する機能を追加する方法はありません。ただし、コンテキスト機能は、正しいタグに関する強力な手がかりを提供します。 「fly」という単語は、前の単語が「a」であることを知っているため、動詞ではなく名詞として機能していると判断できます。\n",
        "\n",
        "単語のコンテキストに依存する機能に対応するには、機能抽出ツールの定義に使用したパターンを修正する必要があります。タグ付けする単語を単に渡すのではなく、ターゲットワードのインデックスとともに、完全な（タグなし）文を渡します。このアプローチは、コンテキスト依存の特徴抽出機能を使用して音声タグ分類子を定義する以下のコードで実証されています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vy9QNAJPUDaI",
        "outputId": "2a6d87a3-82bb-423a-be5e-1aedfcd7f088"
      },
      "source": [
        "def pos_features(sentence, i):\n",
        "    features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                \"suffix(2)\": sentence[i][-2:],\n",
        "                \"suffix(3)\": sentence[i][-3:]}\n",
        "    if i == 0:\n",
        "        features[\"prev-word\"] = \"<START>\"\n",
        "    else:\n",
        "        features[\"prev-word\"] = sentence[i-1]\n",
        "    return features\n",
        "\n",
        "print(pos_features(brown.sents()[0], 8))\n",
        "\n",
        "tagged_sents = brown.tagged_sents(categories='news')\n",
        "featuresets = []\n",
        "for tagged_sent in tagged_sents:\n",
        "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "    for i, (word, tag) in enumerate(tagged_sent):\n",
        "        featuresets.append( (pos_features(untagged_sent, i), tag) )\n",
        "\n",
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion', 'prev-word': 'an'}\n",
            "0.7891596220785678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkR18a0jUDaJ"
      },
      "source": [
        "コンテキスト機能を活用すると、品詞タガーのパフォーマンスが向上することは明らかです。たとえば、分類子は、単語 \"large\"または単語 \"gubernatorial\"の直後に単語がある場合、その単語は名詞である可能性が高いことを学習します。ただし、形容詞に続く場合、単語はおそらく名詞であるという一般化を学習することはできません。前の単語の品詞タグにアクセスできないためです。  \n",
        "\n",
        "一般に、単純な分類器は、各入力を常に他のすべての入力から独立したものとして扱います。多くの状況で、これは完全に理にかなっています。たとえば、名前が男性であるか女性であるかについての決定は、ケースバイケースで行うことができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ADHcJPxUDaJ"
      },
      "source": [
        "### 1.6. Sequence Classification\n",
        "\n",
        "(★ Assignment Remark)\n",
        "\n",
        "関連する分類タスク間の依存関係をキャプチャするために、関連する入力のコレクションに適切なラベル付けを選択する共同分類器モデルを使用できます。品詞タグ付けの場合、さまざまな異なるシーケンス分類器モデルを使用して、特定の文のすべての単語に対して品詞タグを共同で選択できます。\n",
        "\n",
        "連続分類または貪欲なシーケンス分類として知られるシーケンス分類戦略の1つは、最初の入力で最も可能性の高いクラスラベルを見つけ、その回答を使用して次の入力で最適なラベルを見つけることです。  \n",
        "すべての入力にラベルが付けられるまで、プロセスを繰り返すことができます。これは、Lesson 6のバイグラムタガーによって採用されたアプローチです。これは、文の最初の単語の品詞タグを選択することから始まり、前の単語自体と予測に基づいて後続の各単語のタグを選択しました。\n",
        "\n",
        "この戦略は下記のコードで実証されています。まず、特徴抽出関数を拡張してHistory引数を取得する必要があります。  \n",
        "History引数は、これまでの文に対して予測したタグのリストを提供します。各タグの歴史は、内の単語に対応する文。ただし、Historyには、既に分類した単語、つまりターゲット単語の左側の単語のタグのみが含まれることに注意してください。したがって、ターゲットワードの右側にあるワードの一部の機能を調べることは可能ですが、それらのワードのタグを調べることはできません。\n",
        "\n",
        "特徴抽出機能を定義したら、シーケンス分類子の作成に進むことができます。トレーニング中に、注釈付きタグを使用して適切なHistoryを機能抽出器に提供しますが、新しい文にタグを付けるときは、タガー自体の出力に基づいてHistoryリストを生成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "502CzK8kUDaJ"
      },
      "source": [
        "def pos_features(sentence, i, history): \n",
        "     features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                 \"suffix(2)\": sentence[i][-2:],\n",
        "                 \"suffix(3)\": sentence[i][-3:]}\n",
        "     if i == 0:\n",
        "         features[\"prev-word\"] = \"<START>\"\n",
        "         features[\"prev-tag\"] = \"<START>\"\n",
        "     else:\n",
        "         features[\"prev-word\"] = sentence[i-1]\n",
        "         features[\"prev-tag\"] = history[i-1]\n",
        "     return features\n",
        "\n",
        "class ConsecutivePosTagger(nltk.TaggerI):\n",
        "\n",
        "    def __init__(self, train_sents):\n",
        "        train_set = []\n",
        "        for tagged_sent in train_sents:\n",
        "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
        "            history = []\n",
        "            for i, (word, tag) in enumerate(tagged_sent):\n",
        "                featureset = pos_features(untagged_sent, i, history)\n",
        "                train_set.append( (featureset, tag) )\n",
        "                history.append(tag)\n",
        "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "    def tag(self, sentence):\n",
        "        history = []\n",
        "        for i, word in enumerate(sentence):\n",
        "            featureset = pos_features(sentence, i, history)\n",
        "            tag = self.classifier.classify(featureset)\n",
        "            history.append(tag)\n",
        "        return zip(sentence, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGpH8me6UDaJ"
      },
      "source": [
        "(注意: タスクに時間が掛かります）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xpEsVNf_UDaJ",
        "outputId": "c3853951-0f7e-4ac6-f6f6-d24a25c835b8"
      },
      "source": [
        "tagged_sents = brown.tagged_sents(categories='news')\n",
        "size = int(len(tagged_sents) * 0.1)\n",
        "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
        "tagger = ConsecutivePosTagger(train_sents)\n",
        "print(tagger.evaluate(test_sents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7980528511821975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luo7yDfCUDaJ"
      },
      "source": [
        "## Lesson 2. Further Examples of Supervised Classification\n",
        "\n",
        "### 2.1. Sentence Segmentation\n",
        "\n",
        "※ Assignment Remark\n",
        "\n",
        "文のセグメンテーションは、句読点の分類タスクと見なすことができます。ピリオドや疑問符など、文を終了させる可能性のある記号に出会うたびに、前の文を終了するかどうかを判断する必要があります。\n",
        "\n",
        "最初のステップは、すでに文にセグメント化されているいくつかのデータを取得し、それを特徴の抽出に適した形式に変換することです。\n",
        "\n",
        "ここで、トークンは個々の文からのトークンのマージされたリストであり、境界はすべての文境界トークンのインデックスを含むセットです。次に、句読点が文の境界を示しているかどうかを判断するために使用されるデータの特徴を指定する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dfrsWZBLUDaK",
        "outputId": "70b7a7fe-c9a0-49eb-899e-3374f5632a7e"
      },
      "source": [
        "nltk.download('treebank')\n",
        "sents = nltk.corpus.treebank_raw.sents()\n",
        "\n",
        "def punct_features(tokens, i):\n",
        "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
        "            'prev-word': tokens[i-1].lower(),\n",
        "            'punct': tokens[i],\n",
        "            'prev-word-is-one-char': len(tokens[i-1]) == 1}\n",
        "\n",
        "tokens = []\n",
        "boundaries = set()\n",
        "offset = 0\n",
        "for sent in sents:\n",
        "    tokens.extend(sent)\n",
        "    offset += len(sent)\n",
        "    boundaries.add(offset-1)\n",
        "\n",
        "\n",
        "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
        "               for i in range(1, len(tokens)-1)\n",
        "               if tokens[i] in '.?!']\n",
        "\n",
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "0.936026936026936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5afUHOq7UDaK"
      },
      "source": [
        "この分類子を使用して文のセグメンテーションを実行するには、各句読点をチェックして、境界としてラベル付けされているかどうかを確認します。境界マークで単語のリストを分割します。以下のコードは、これを行う方法を示しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qECvM1QFUDaK"
      },
      "source": [
        "def segment_sentences(words):\n",
        "    start = 0\n",
        "    sents = []\n",
        "    for i, word in enumerate(words):\n",
        "        if i != len(words)-1 and word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
        "            sents.append(words[start:i+1])\n",
        "            start = i+1\n",
        "    if start < len(words):\n",
        "        sents.append(words[start:])\n",
        "    return sents\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBS5yKSWUDaK"
      },
      "source": [
        "対話を処理するとき、発話を話者によって実行されるアクションの一種と考えると便利です。この解釈は、「私はあなたを許します」または「あなたはその丘に登ることはできないに違いない」などのパフォーマンスのあるステートメントに対して最も簡単です。ただし、挨拶、質問、回答、主張、説明はすべて、音声ベースのアクションの一種と考えることができます。対話の発話の根底にある対話行為を認識する ことは、会話を理解する上で重要な最初のステップになります。\n",
        "\n",
        "NPSチャットコーパスは、 インスタントメッセージングセッションからの10,000を超える投稿で構成されています。これらの投稿にはすべて、「Statement」、「Emotion」、「ynQuestion」、「Continuer」などの15種類の対話行為のいずれかのラベルが付いています。したがって、このデータを使用して、新しいインスタントメッセージング投稿の対話行為の種類を識別することができる分類子を構築できます。最初のステップは、基本的なメッセージングデータを抽出することです。xml_posts（）を呼び出して、各投稿のXML注釈を表すデータ構造を取得します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-jHTJuykUDaK",
        "outputId": "8a4596dc-3fb1-4e27-ba16-af91d1e60f8e"
      },
      "source": [
        "nltk.download('nps_chat')\n",
        "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlT6bLqNUDaK"
      },
      "source": [
        "次に、投稿に含まれる単語をチェックする簡単な特徴抽出機能を定義します."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DsjX8QGsUDaK"
      },
      "source": [
        "def dialogue_act_features(post):\n",
        "    features = {}\n",
        "    for word in nltk.word_tokenize(post):\n",
        "        features['contains({})'.format(word.lower())] = True\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwvJ0kRBUDaK"
      },
      "source": [
        "最後に、各投稿に特徴抽出機能を適用して（post.get（'class'）を使用して投稿の対話行為タイプを取得する）トレーニングおよびテストデータを構築し、新しい分類子を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2B-NwUJDUDaL",
        "outputId": "264251bb-5727-4138-9f38-4143055734a2"
      },
      "source": [
        "nltk.download('punkt')\n",
        "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
        "               for post in posts]\n",
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "0.668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT_8qcHUUDaL"
      },
      "source": [
        "### 2.3. テキストの含意の認識\n",
        "\n",
        "テキスト含意（RTE）の認識は、特定のテキストTが「仮説」と呼ばれる別のテキストを含意するかどうかを決定するタスクです。これまでに、4つのRTEチャレンジがあり、競合するチームが開発とテストの共有データを利用できるようになりました。以下は、チャレンジ3開発データセットのテキスト/仮説のペアの例です。ラベルTrueは含意が成り立つことを示し、Falseは含意が成り立たないことを示します。\n",
        "\n",
        "チャレンジ3、ペア34（True）\n",
        "\n",
        "T：パルビズダブディは、ロシア、中国、中央アジアの4つの旧ソビエト連邦を結びつけてテロと戦う、駆け出しの協会である上海協力機構（SCO）の会議でイランを代表していました。\n",
        "\n",
        "H：中国はSCOのメンバーです。\n",
        "\n",
        "チャレンジ3、ペア81（False）\n",
        "\n",
        "T：NCの定款によれば、LLC会社のメンバーはH.ネルソンビーバーズ、III、H。チェスタービーバーズ、ジェニービーバーズスチュワートです。\n",
        "\n",
        "H：Jennie Beavers Stewartは、Carolina Analytical Laboratoryの株主です。\n",
        "\n",
        "テキストと仮説の関係は論理的含意を意図するものではなく、むしろ、テキストが仮説を真にするための合理的な証拠を提供すると人間が結論付けるかどうかを強調する必要があります。\n",
        "\n",
        "RTEを分類タスクとして扱うことができます。このタスクでは、各ペアのTrue / Falseラベルを予測しようとします。このタスクに対する成功したアプローチには、構文解析、セマンティクス、および実世界の知識の組み合わせが含まれる可能性が高いようですが、RTEの初期の試みの多くは、テキストと単語レベルでの仮説の類似性に基づいて、浅い分析でかなり良い結果を達成しました 理想的なケースでは、含意がある場合、仮説によって表されるすべての情報もテキストに存在するはずです。逆に、テキストにない情報が仮説で見つかった場合、含意はありません。\n",
        "\n",
        "以下のRTE特徴検出器では、単語（つまり、単語の種類）を情報のプロキシとして機能させ、特徴は単語の重複の程度と、仮説にはあるがテキストにはない単語の数をカウントします（メソッドhyp_extra（）によってキャプチャされます）。  \n",
        "すべての単語が同じように重要であるわけではありません。名前付きエンティティの言及は、人、組織、場所などの名前がより重要である可能性が高いため、単語 sとne（名前付きエンティティ）の個別の情報を抽出するように動機付けられます。  \n",
        "さらに、いくつかの高周波機能ワードは、「ストップワード」として除外されます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SCsset35UDaL"
      },
      "source": [
        "def rte_features(rtepair):\n",
        "    extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        "    features = {}\n",
        "    features['word_overlap'] = len(extractor.overlap('word'))\n",
        "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
        "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
        "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrRofAAvUDaL"
      },
      "source": [
        "これらの機能の内容を説明するために、前に示したテキスト/仮説ペア34のいくつかの属性を調べます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_4neSgjRUDaL",
        "scrolled": true,
        "outputId": "7e3a89c9-5142-4383-e2a3-4b3368afcc4b"
      },
      "source": [
        "nltk.download('rte')\n",
        "rtepair = nltk.corpus.rte.pairs(['rte3_dev.xml'])[33]\n",
        "extractor = nltk.RTEFeatureExtractor(rtepair)\n",
        "print(extractor.text_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]   Package rte is already up-to-date!\n",
            "{'republics', 'binds', 'that', 'at', 'operation', 'meeting', 'China', 'Iran', 'Co', 'Asia', 'Soviet', 'representing', 'former', 'fledgling', 'Russia', 'association', 'Organisation', 'was', 'terrorism.', 'Davudi', 'SCO', 'fight', 'Parviz', 'Shanghai', 'together', 'four', 'central'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zoocH7OeUDaL",
        "outputId": "d4add8ab-ceae-4fbe-9a99-47d322f2af1e"
      },
      "source": [
        " print(extractor.hyp_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'member', 'SCO.', 'China'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SV_d7uOlUDaM",
        "outputId": "972acfe6-cfcc-4be2-e944-19832ea480eb"
      },
      "source": [
        " print(extractor.overlap('word'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "set()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3taQlgzOUDaM",
        "outputId": "bcec5c2d-d0ce-429d-eb1c-29784eb35201"
      },
      "source": [
        "print(extractor.overlap('ne'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'China'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J3nnZNHkUDaM",
        "outputId": "43dc0ce4-b4ab-4108-9038-51fc61cd362f"
      },
      "source": [
        "print(extractor.hyp_extra('word'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'member'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUcMdohUDaM"
      },
      "source": [
        "### 2.4. 大規模データセットへのスケールアップ\n",
        "\n",
        "Pythonは、基本的なテキスト処理と特徴抽出を実行するための優れた環境を提供します。ただし、機械学習方法に必要な数値集中計算をCなどの低レベル言語とほぼ同じ速度で実行することはできないとされてきました。したがって、純粋なPython機械学習実装（nltk.NaiveBayesClassifierなど）を使用しようとすると、大規模なデータセットでは、学習アルゴリズムの完了に不合理な時間とメモリがかかることがあります。  \n",
        "しかしながら、近年では、Pythonテクノロジの向上により、C言語等よりもより早く、GPU並列化等を組み込むことが出来るライブラリが多数存在する上に、JIT（Just in time)コンパイラの組み込みにより、C言語と遜色ない速度で検証することが出来るようになってきました。このため、ディープラーニング等の計算量の高いアルゴリズムへの検証実装等は、ほぼPythonの独擅場となってきています。\n",
        "\n",
        "大量のトレーニングデータまたは多数の機能を使用して分類器をトレーニングする予定がある場合は、外部の機械学習パッケージとインターフェイスするためのNLTKの機能を検討することをお勧めします。これらのパッケージがインストールされると、NLTKはそれらを（システムコールを介して）透過的に呼び出して、純粋なPython分類子の実装よりもはるかに高速に分類子モデルをトレーニングできます。NLTKでサポートされている推奨機械学習パッケージのリストについては、NLTK Webページを参照してください。\n",
        "また、機械学習を行う場合は、Scikit-Learn(https://scikit-learn.org/) 等を使うことをお勧めします。\n",
        "\n",
        "## Lesson 3. Evaluation\n",
        "分類モデルがパターンを正確にキャプチャしているかどうかを判断するには、そのモデルを評価する必要があります。この評価の結果は、モデルの信頼性を決定するために、そしてどのような目的でモデルを使用できるかを決定するために重要です。評価は、モデルの将来の改善を行う上で私たちを導くための効果的なツールにもなります\n",
        "\n",
        "### 3.1. Test Set\n",
        "\n",
        "ほとんどの評価手法は、テストセット （または評価セット）の入力に対して生成されたラベルを、それらの入力の正しいラベルと比較することにより、モデルのスコアを計算します。通常、このテストセットの形式はトレーニングセットと同じです。ただし、テストセットがトレーニングコーパスとは異なることは非常に重要です。トレーニングセットをテストセットとして単純に再利用する場合、新しいサンプルに一般化する方法を学習せずに、入力を単純に記憶するモデルは、誤解を招くほど高いスコアを受け取ります。\n",
        "\n",
        "テストセットを作成するとき、テストに使用できるデータの量とトレーニングに使用できる量の間にトレードオフがしばしばあります。少数のバランスのとれたラベルと多様なテストセットを持つ分類タスクの場合、わずか100の評価インスタンスで意味のある評価を実行できます。  \n",
        "ただし、分類タスクに多数のラベルがある場合、または非常にまれなラベルが含まれている場合は、最も頻度の低いラベルが少なくとも50回発生するようにテストセットのサイズを選択する必要があります。  \n",
        "さらに、テストセットに1つのドキュメントから描画されたインスタンスなど、密接に関連する多くのインスタンスが含まれる場合、テストセットのサイズを大きくして、この多様性の欠如が評価結果を歪めないようにする必要があります。\n",
        "\n",
        "テストセットを選択する際のもう1つの考慮事項は、テストセットのインスタンスと開発セットのインスタンスの類似度です。これら2つのデータセットが類似しているほど、評価結果が他のデータセットに一般化されるという確信が低くなります。たとえば、品詞タグ付けタスクについて考えてみましょう。極端な場合、単一のジャンル（ニュース）を反映するデータソースから文をランダムに割り当てることにより、トレーニングセットとテストセットを作成できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6APXOm3UUDaM"
      },
      "source": [
        "import random\n",
        "from nltk.corpus import brown\n",
        "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
        "random.shuffle(tagged_sents)\n",
        "size = int(len(tagged_sents) * 0.1)\n",
        "train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRymIoA2UDaM"
      },
      "source": [
        "この場合、テストセットはトレーニングセットと非常によく似ています。トレーニングセットとテストセットは同じジャンルから取得されるため、評価結果が他のジャンルに一般化されるとは確信できません。さらに悪いことに、random.shuffle（）の呼び出しのために、 テストセットにはトレーニングに使用された同じドキュメントから取得された文が含まれています。文書内に一貫したパターンがある場合（たとえば、特定の品詞タグが特に頻繁に出現する場合など）、その違いは開発セットとテストセットの両方に反映されます。やや優れたアプローチは、トレーニングセットとテストセットが異なるドキュメントから取得されるようにすることです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qrn-B7qsUDaM"
      },
      "source": [
        "file_ids = brown.fileids(categories='news')\n",
        "size = int(len(file_ids) * 0.1)\n",
        "train_set = brown.tagged_sents(file_ids[size:])\n",
        "test_set = brown.tagged_sents(file_ids[:size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mLuXAkwnUDaN"
      },
      "source": [
        "train_set = brown.tagged_sents(categories='news')\n",
        "test_set = brown.tagged_sents(categories='fiction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki2xqNduUDaN"
      },
      "source": [
        "### 3.2. Accuracy\n",
        "\n",
        "分類器を評価するために使用することができる最も簡単なメトリック、 精度、分類器が正しくラベルされたことをテストセットでの入力の割合を測定します。たとえば、80個の名前を含むテストセットで正しい名前を60回予測する名前性別分類子の精度は60/80 = 75％です。関数nltk.classify.accuracy（）は、特定のテストセットで分類子モデルの精度を計算します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gigjxe6fUDaN"
      },
      "source": [
        "    classifier = nltk.NaiveBayesClassifier.train(train_set) f\n",
        "    print(nltk.classify.accuracy(classifier,test_set))\n",
        "    print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set))) \n",
        "    \n",
        "    0.75\n",
        "    \n",
        "分類子の精度スコアを解釈するときは、テストセット内の個々のクラスラベルの頻度を考慮することが重要です。  \n",
        "たとえば、単語bankが出現するたびに正しい単語の意味を決定する分類器を考えます。Wired Bank Newsのテキストでこの分類器を評価すると、金融機関のsenseが20回のうち19回現れることがあります。その場合、95％の精度はモデルでその精度を達成できるため、ほとんど印象的ではありません。それは常に金融機関をsenseとして返します。  \n",
        "ただし、代わりに、最も頻度の高い単語の意味が40％の頻度である、よりバランスのとれたコーパスで分類器を評価する場合、95％の精度スコアがはるかに良い結果になります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLEBuNMhUDaN"
      },
      "source": [
        "### 3.3. Precision and Recall\n",
        "\n",
        "精度スコアが誤解を招く可能性がある別の例は、特定のタスクに関連するドキュメントの検索を試みる情報検索などの「検索」タスクです。無関係なドキュメントの数は、関連するドキュメントの数をはるかに上回るため、すべてのドキュメントを無関係とラベル付けするモデルの精度スコアは、100％に非常に近くなります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vipWzxINUDaN"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqohxNTDUDaN"
      },
      "source": [
        "したがって、上図に示されている4つのカテゴリのそれぞれのアイテムの数に基づいて、検索タスクに異なるメジャーセットを採用するのが一般的です。\n",
        "\n",
        " - True-Positive (真陽性) は、関連性があると正しく識別された関連項目です。\n",
        " - True-Negative (真陰性) は、無関係であると正しく識別した無関係なアイテムです。\n",
        " - False-Positive (偽陽性) 、誤検知（またはタイプIエラー）は、関連性があると間違って診断した関連性のないアイテムです。\n",
        " - False-Nevative (偽陰性、またはタイプIIエラー）は、関連性があるのに不適切であると誤って特定した関連項目です。\n",
        " \n",
        "これらの4つの数値が与えられると、次のメトリックを定義できます。\n",
        "\n",
        "- Precision (精度) は、特定したアイテムのうちどれだけが関連していたかを示すもので、TP /（TP + FP）です。\n",
        "- Recall (再現率) は、特定した関連アイテムの数がTP /（TP + FN）であることを示しています。\n",
        "- F-Measure (F値)（またはF-スコア（単一のスコアを与えるための精度と再現率を兼ね備え）、精度と再現率の調和平均であると定義される.　  \n",
        "(2 x 精度 x リコール）/（精度 + リコール）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHKKCL2qUDaN"
      },
      "source": [
        "### 3.4. Confusion Matrix\n",
        "\n",
        "3つ以上のラベルを使用して分類タスクを実行する場合、どのタイプの間違いに基づいてモデルによって行われたエラーを再分割することが有益である可能性があります。混同行列は、各セル(表であるi、j)はラベル頻度を示し、jが正しいラベルとした場合に、iが予測され、その数や割合をカウントする。したがって、対角エントリ（つまり、セル| ii |）は正しく予測されたラベルを示し、非対角エントリはエラーを示します。次の例では、Lesson 5で開発されたバイグラムタガーの混同行列を生成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9MRGnZ5EUDaN",
        "outputId": "695d7c19-b76c-4f9f-becf-e26c3716eee0"
      },
      "source": [
        "t0 = nltk.DefaultTagger('NN')\n",
        "t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
        "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
        "t2.evaluate(test_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723226703755216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gBfzHiMGUDaO",
        "outputId": "251cf526-b01e-4275-8bfd-6b81d96ceaf6"
      },
      "source": [
        "def tag_list(tagged_sents):\n",
        "    return [tag for sent in tagged_sents for (word, tag) in sent]\n",
        "def apply_tagger(tagger, corpus):\n",
        "    return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]\n",
        "gold = tag_list(brown.tagged_sents(categories='editorial'))\n",
        "test = tag_list(apply_tagger(t2, brown.tagged_sents(categories='editorial')))\n",
        "cm = nltk.ConfusionMatrix(gold, test)\n",
        "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    |                                         N                      |\n",
            "    |      N      I      A      J             N             V      N |\n",
            "    |      N      N      T      J      .      S      ,      B      P |\n",
            "----+----------------------------------------------------------------+\n",
            " NN | <11.9%>  0.0%      .   0.2%      .   0.0%      .   0.2%   0.0% |\n",
            " IN |   0.0%  <9.0%>     .      .      .   0.0%      .      .      . |\n",
            " AT |      .      .  <8.6%>     .      .      .      .      .      . |\n",
            " JJ |   1.7%      .      .  <4.0%>     .      .      .   0.0%   0.0% |\n",
            "  . |      .      .      .      .  <4.8%>     .      .      .      . |\n",
            "NNS |   1.4%      .      .      .      .  <3.3%>     .      .   0.0% |\n",
            "  , |      .      .      .      .      .      .  <4.4%>     .      . |\n",
            " VB |   1.0%      .      .   0.0%      .      .      .  <2.4%>     . |\n",
            " NP |   1.0%      .      .   0.0%      .      .      .      .  <1.9%>|\n",
            "----+----------------------------------------------------------------+\n",
            "(row = reference; col = test)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqvzTdLOUDaO"
      },
      "source": [
        "### 3.5. Cross Validation\n",
        "\n",
        "モデルを評価するには、注釈付きデータの一部をテストセット用に予約する必要があります。すでに述べたように、テストセットが小さすぎる場合、評価は正確ではない可能性があります。ただし、テストセットを大きくすることは、通常、トレーニングセットを小さくすることを意味し、限られた量の注釈付きデータが利用可能な場合、パフォーマンスに大きな影響を与える可能性があります。\n",
        "\n",
        "この問題の解決策の1つは、異なるテストセットで複数の評価を実行し、それらの評価から得られたスコアを相互検証と呼ばれる手法で結合することです。特に、元のコーパスをfolds と呼ばれるN個のサブセットに分割します。これらの各フォールドについて、そのフォールド内のデータを除くすべてのデータを使用してモデルをトレーニングし、フォールド上でそのモデルをテストします。個々のフォールドが小さすぎて正確な評価スコアを単独で提供できない場合でも、複合評価スコアは大量のデータに基づいているため、非常に信頼性が高くなります。\n",
        "\n",
        "クロスバリデーションを使用するもう1つの重要な利点は、異なるトレーニングセット間でパフォーマンスがどれほど大きく変化するかを調べることができることです。N個すべてのトレーニングセットについて非常に類似したスコアを取得する場合 、スコアが正確であるとかなり確信で​​きます。一方、N個のトレーニングセットでスコアが大きく異なる場合は、評価スコアの精度についておそらく懐疑的です。\n",
        "\n",
        "## Lesson 4. Desicion Tree\n",
        "\n",
        "決定木は、単純なフローチャートである入力値の選択ラベルこと。このフローチャートは、特徴値をチェックする決定ノードと、ラベルを割り当てるリーフノードで構成されています。入力値のラベルを選択するには、ルートノードと呼ばれるフローチャートの初期決定ノードから始めます。このノードには、入力値の機能の1つをチェックし、その機能の値に基づいてブランチを選択する条件が含まれています。入力値を説明するブランチに続いて、入力値の機能に新しい条件を設定した新しい決定ノードに到達します。入力値のラベルを提供するリーフノードに到達するまで、各ノードの条件によって選択されたブランチを追跡し続けます。 以下の図は 名前性別タスクのデシジョンツリーモデルの例を示します。\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "デシジョンツリーを作成したら、それを使用して新しい入力値にラベルを割り当てるのは簡単です。それほど簡単ではないのは、特定のトレーニングセットをモデル化する決定木を構築する方法です。しかし、意思決定ツリーを構築するための学習アルゴリズムを検討する前に、コーパスに最適な「意思決定の切り株」を選択する、より単純なタスクを検討します。意思決定の切り株は、単一の機能に基づいて入力を分類する方法を決定する単一のノードを持つ決定ツリーです。可能なフィーチャ値ごとに1つのリーフが含まれ、その値を持つフィーチャの入力に割り当てられるクラスラベルを指定します。決定の切り株を作成するには、最初にどの機能を使用するかを決定する必要があります。最も簡単な方法は、可能な機能ごとに意思決定の切り株を作成し、トレーニングデータでどれが最高の精度を達成するかを確認することです。ただし、以下で説明する他の選択肢もあります。機能を選択したら、トレーニングセット内の選択した例（選択した機能にその値がある例）の最も頻繁なラベルに基づいて各リーフにラベルを割り当てることにより、決定スタンプを作成できます。\n",
        "\n",
        "決定切り株を選択するためのアルゴリズムを考えると、より大きな決定木を成長させるためのアルゴリズムは簡単です。まず、分類タスクの全体的な最適な決定スタンプを選択することから始めます。次に、トレーニングセットの各リーフの精度をチェックします。十分な精度を達成できない葉は、葉へのパスによって選択されたトレーニングコーパスのサブセットでトレーニングされた新しい決定切り株に置き換えられます。たとえば、「k」で始まらず、母音または「l」で終わらないトレーニングセット名のサブセットでトレーニングされた新しい左端の葉を新しい決定切り株に置き換えることにより、4.1 の決定木を成長させることができます。 」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT15DmS4UDaO"
      },
      "source": [
        "### 4.1. Entropy and Information Gain\n",
        "\n",
        "前述したように、意思決定の切り株の最も有益な機能を識別するための方法がいくつかあります。情報ゲインと呼ばれる人気のある代替手段は、特定の機能を使用して入力値を分割したときに、入力値がどれだけ整理されるかを測定します。入力値の元のセットがどの程度無秩序であるかを測定するために、ラベルのエントロピーを計算します。これは、入力値に非常に多様なラベルがある場合は高く、多くの入力値がすべて同じラベルを持つ場合は低くなります。特に、エントロピーは、各ラベルの確率の合計にその同じラベルの対数確率を掛けたものとして定義されます。\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "以下のコードは、ラベルのリストのエントロピーを計算する方法です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BWNKIUwqUDaO"
      },
      "source": [
        "import math\n",
        "def entropy(labels):\n",
        "    freqdist = nltk.FreqDist(labels)\n",
        "    probs = [freqdist.freq(l) for l in freqdist]\n",
        "    return -sum(p * math.log(p,2) for p in probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jC7p6RgeUDaO",
        "outputId": "8c6d1577-6e77-4a1c-e21e-9676910491e3"
      },
      "source": [
        "print(entropy(['male', 'male', 'male', 'male'])) \n",
        "print(entropy(['male', 'female', 'male', 'male']))\n",
        "print(entropy(['female', 'male', 'female', 'male']))\n",
        "print(entropy(['female', 'female', 'male', 'female']))\n",
        "print(entropy(['female', 'female', 'female', 'female'])) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0\n",
            "0.8112781244591328\n",
            "1.0\n",
            "0.8112781244591328\n",
            "-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nms-zvXFUDaO"
      },
      "source": [
        "入力値の元のラベルのセットのエントロピーを計算したら、決定スタンプを適用すると、ラベルがどの程度整理されるかを決定できます。そのために、決定切り株の各葉のエントロピーを計算し、それらの葉のエントロピー値の平均（各葉のサンプル数で重み付け）を取得します。情報ゲインは、元のエントロピーからこの新しい減少したエントロピーを引いたものに等しくなります。情報ゲインが高いほど、入力値をコヒーレントグループに分割する決定スタンプの仕事がより良くなるため、情報ゲインが最も高い決定スタンプを選択することで決定木を構築できます。\n",
        "\n",
        "決定木のもう1つの考慮事項は効率です。上記の決定スタンプを選択するための簡単なアルゴリズムは、考えられるすべての機能に対して候補決定スタンプを構築する必要があり、構築された決定ツリー内のすべてのノードに対してこのプロセスを繰り返す必要があります。以前に評価された例に関する情報を保存および再利用することにより、トレーニング時間を短縮するための多くのアルゴリズムが開発されました。\n",
        "\n",
        "決定木には多くの有用な性質があります。そもそも、理解しやすく、解釈しやすいものです。これは、意思決定ツリーの最上部付近で特に当てはまります。通常、学習アルゴリズムは非常に有用な機能を見つけることができます。決定木は、多くの階層的なカテゴリの区別を行うことができる場合に特に適しています。たとえば、決定木は系統樹のキャプチャに非常に効果的です。\n",
        "\n",
        "ただし、決定木にはいくつかの欠点もあります。1つの問題は、決定ツリーの各ブランチがトレーニングデータを分割するため、ツリーの下位ノードをトレーニングするために使用できるトレーニングデータの量が非常に少なくなる可能性があることです。その結果、これらの下位決定ノードは\n",
        "\n",
        "トレーニングセットをオーバーフィットし、基礎となる問題の言語的に重要なパターンではなく、トレーニングセットの特異性を反映する学習パターン。この問題の1つの解決策は、トレーニングデータの量が少なくなりすぎるとノードの分割を停止することです。別の解決策は、完全な決定ツリーを成長させることですが、その後、開発テストのパフォーマンスを改善しない決定ノードを 除去することです。\n",
        "\n",
        "デシジョンツリーの2番目の問題は、フィーチャが互いに比較的独立して動作する場合でも、フィーチャを特定の順序で強制的にチェックすることです。たとえば、ドキュメントをトピック（スポーツ、自動車、殺人ミステリーなど）に分類する場合、hasword（football）などの機能は、他の機能値に関係なく、特定のラベルを非常に示します。デシジョンツリーの上部付近にはスペースが限られているため、これらの機能のほとんどは、ツリー内のさまざまなブランチで繰り返す必要があります。そして、ツリーを下るにつれて分岐の数が指数関数的に増加するため、繰り返しの量は非常に大きくなる可能性があります。\n",
        "\n",
        "関連する問題は、ディシジョンツリーが、正しいラベルの弱い予測子である機能の使用に適していないことです。これらの機能は比較的小さな漸進的な改善を行うため、決定ツリーで非常に低い頻度で発生する傾向があります。しかし、決定木学習者がこれらの機能を使用するのに十分なほど下降した時点では、どのような効果があるかを確実に判断するのに十分なトレーニングデータが残っていません。代わりに、トレーニングセット全体でこれらの機能の効果を見ることができれば、ラベルの選択にどのように影響するかについて結論を出すことができるかもしれません。\n",
        "\n",
        "ディシジョンツリーでは、特定の順序で機能をチェックする必要があるため、比較的独立した機能を活用する能力が制限されます。次に説明する単純なベイズ分類法は、すべての機能を「並行して」動作させることにより、この制限を克服します。"
      ]
    }
  ]
}